{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO RE-RUN\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid,cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.externals.joblib import Memory\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "from mlxtend.classifier import StackingCVClassifier, StackingClassifier\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from operator import truediv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required domain methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../src/\")\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter\n",
    "import MLpipeline as MLpipeline\n",
    "from FeatFilter import FeatFilter\n",
    "import readmision_methods as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeEncounter = \"last\" # ['first','last']\n",
    "typeHypothesis = \"early_readmission_vs_none\" # ['all_readmisssion_vs_none','early_readmission_vs_none']\n",
    "typeDataFeatures = \"extended_extra_diag_3\" # [\"reduced\",\"extended','extended_extra','extended_extra_diag_1','extended_extra_diag_3']\n",
    "typeDataExperiment = \"all\" #[\"all\", \"disease\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "tr_thrs = 0.7 # [0.1,0.2,0.4,0.6,1.0]\n",
    "ts_thr = 1 - tr_thrs\n",
    "\n",
    "selected_filters = [3,6,7,8,9]\n",
    "fs_methods = [\"none\"] #[\"none\",\"combine_fs\",\"lasso_fs\",\"rfe_rf_fs\"]\n",
    "cls_methods = [\"logReg\"] #[\"rf\",\"svmRBF\",\"logReg\",\"knn\",\"nn\",\"gbt\"]\n",
    "lms = [\"recall\"] #[\"f1_weighted\",\"average_precision\",\"roc_auc\",\"recall\"]\n",
    "sm_types = [\"none\"] #[\"none\",\"after\"]tr_thrs\n",
    "sm_method = \"sm_smote\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(67182, 69)\n",
      "\n",
      "SHAPE FILTERED:\n",
      "(45779, 69)\n",
      "\n",
      "Rows by class type:\n",
      "[0 1] 39785 5994\n",
      "\n",
      "Train: (32045, 68) Test: (13734, 68)\n",
      "[['patient_filter', 5], ['admision_discharge_filter', 29], ['hospital_filter', 9], ['Visits_filter', 8], ['diagnosis_filter', 14], ['medicines_filter', 15], ['extra_filter', 68], ['none_filter', 17], ['no_diagnosis_filter', 60], ['selected_filter', 17]]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df_all = rm.load_data(typeEncounter, typeDataFeatures)\n",
    "print \"\\nSHAPE:\"\n",
    "print df_all.shape\n",
    "\n",
    "#Filter data by class\n",
    "df_all = rm.filter_data_by_class(df_all, typeHypothesis)\n",
    "print \"\\nSHAPE FILTERED:\"\n",
    "print df_all.shape\n",
    "\n",
    "print \"\\nRows by class type:\"\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)\n",
    "\n",
    "#Train (on ts_thr percentage) & Test\n",
    "X_train, X_test, y_train, y_test = MLpipeline.train_test_partition(df_all, ts_thr)\n",
    "columns = df_all.columns\n",
    "\n",
    "print \"\\nTrain:\", X_train.shape, \"Test:\",  X_test.shape\n",
    "\n",
    "#Create filters\n",
    "featFilters = rm.create_filters(df_all)\n",
    "print [[f[0],np.sum(f[1])] for f in featFilters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_inner_pipeline(param_prefix, catCols,reducedCols, hyperparams, cls_method, featsToFilter=None):\n",
    "    \n",
    "    # Create a temporary folder to store the transformers of the pipeline\n",
    "    cachedir = mkdtemp()\n",
    "    memory = Memory(cachedir=cachedir, verbose=0)                        \n",
    "    \n",
    "    basePipeline = Pipeline([\n",
    "            (\"FeatFilter\", FeatFilter(featsToFilter)),\n",
    "            (\"Imputer\", TypeFeatImputer(catCols, reducedCols)),\n",
    "            (\"Scaler\", StandardScaler()),\n",
    "            (\"Variance\", VarianceThreshold(threshold=0.0))\n",
    "        ], memory = memory)\n",
    "\n",
    "    params = {}\n",
    "    pipe = Pipeline(list(basePipeline.steps))\n",
    "\n",
    "    if cls_method == \"knn\":\n",
    "        pipe.steps.append((cls_method, KNeighborsClassifier()))\n",
    "                        \n",
    "    if cls_method == \"rf\":\n",
    "        pipe.steps.append((cls_method, RandomForestClassifier(n_jobs=-1,random_state=42)))\n",
    "\n",
    "    if cls_method == \"nb\":\n",
    "        pipe.steps.append((cls_method, GaussianNB()))\n",
    "\n",
    "    if cls_method == \"logReg\":\n",
    "        pipe.steps.append((cls_method, LogisticRegression(random_state=42)))\n",
    "\n",
    "    #Add param prefix\n",
    "    pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "    new_pm = {}\n",
    "    for key, values in pm.iteritems():\n",
    "        key = param_prefix + key\n",
    "        new_pm[key] = values\n",
    "    params.update(new_pm) \n",
    "                    \n",
    "    return pipe,params\n",
    "\n",
    "def evaluate(name, y_test, y_pred):\n",
    "\n",
    "    test_f1_w = metrics.f1_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "    test_p, test_r, test_f1, test_s = metrics.precision_recall_fscore_support(y_test, y_pred,labels=None,average=None, sample_weight=None)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    test_auc = metrics.auc(fpr, tpr)                \n",
    "    cm_test = metrics.confusion_matrix(y_test, y_pred)\n",
    "    tn = cm_test[0,0]\n",
    "    fp = cm_test[0,1]\n",
    "    fn = cm_test[1,0]\n",
    "    tp = cm_test[1,1]\n",
    "    test_sens = test_r[1]\n",
    "    test_spec = tn / float(tn+fp)\n",
    "\n",
    "    print \"\\nEvaluation:\", name\n",
    "    print \"*******************\"\n",
    "    print          \n",
    "    print \"TEST AUC: %0.3f\" % (test_auc)                \n",
    "    print \"TEST sensitivity:\", test_sens\n",
    "    print \"TEST Specificity:\", test_spec\n",
    "    print\n",
    "    print \"TEST f1 (weighted): %0.3f\" % (test_f1_w)\n",
    "    print \"TEST f1 [c=0,1]\", test_f1\n",
    "    print \"TEST Precision [c=0,1]:\", test_p\n",
    "    print \"TEST Recall [c=0,1]:\", test_r  \n",
    "    \n",
    "    print \"Confussion matrix:\"\n",
    "    print \"         | PRED\"\n",
    "    print \"REAL-->  v \"\n",
    "    print cm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num pipelines: 6\n",
      "Selected filters: [3, 6, 7, 8, 9]\n",
      "Params: [{'pipeline-1__logReg__penalty': ['l1', 'l2'], 'pipeline-1__logReg__C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 10], 'pipeline-1__logReg__class_weight': ['balanced']}, {'pipeline-2__logReg__class_weight': ['balanced'], 'pipeline-2__logReg__penalty': ['l1', 'l2'], 'pipeline-2__logReg__C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 10]}, {'pipeline-3__logReg__class_weight': ['balanced'], 'pipeline-3__logReg__C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 10], 'pipeline-3__logReg__penalty': ['l1', 'l2']}, {'pipeline-4__logReg__C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 10], 'pipeline-4__logReg__penalty': ['l1', 'l2'], 'pipeline-4__logReg__class_weight': ['balanced']}, {'pipeline-5__logReg__class_weight': ['balanced'], 'pipeline-5__logReg__penalty': ['l1', 'l2'], 'pipeline-5__logReg__C': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 10]}, {'meta-randomforestclassifier__criterion': ['entropy', 'gini'], 'meta-randomforestclassifier__max_depth': [None, 2, 4, 6, 8], 'meta-randomforestclassifier__class_weight': ['balanced_subsample'], 'meta-randomforestclassifier__n_estimators': [50, 100, 200, 300, 500]}]\n"
     ]
    }
   ],
   "source": [
    "pipes = []\n",
    "params = []\n",
    "\n",
    "num_pipeline = 1\n",
    "for sel in selected_filters:\n",
    "    for cls_method  in cls_methods:\n",
    "        \n",
    "        n,f = featFilters[sel]\n",
    "\n",
    "        #Get categoric/numeric\n",
    "        f_cols = columns[:-1][f==1].values.tolist()\n",
    "        f_cols.append(\"readmitted\")       \n",
    "        catCols, reducedCols = rm.compute_type_features(f_cols)\n",
    "\n",
    "        #Get hyperparams\n",
    "        hyperparams = np.load(\"../src/default_hyperparams.npy\")\n",
    "\n",
    "        #Create pipeline\n",
    "        prefix = \"pipeline-\" + str(num_pipeline) + \"__\"\n",
    "        pipe, param = create_inner_pipeline(prefix, catCols, reducedCols, hyperparams,cls_method, f)\n",
    "\n",
    "        #Add results\n",
    "        pipes.append(pipe)\n",
    "        params.append(param)\n",
    "        \n",
    "        num_pipeline += 1\n",
    "\n",
    "#Add meta hyperparams\n",
    "param_prefix = \"meta-\"\n",
    "meta_params = {}\n",
    "new_pm = {}\n",
    "\n",
    "pm = hyperparams[hyperparams[:,1] == \"rf\",2][0]\n",
    "\n",
    "for key, values in pm.iteritems():\n",
    "    key = param_prefix + key.replace(\"rf\",\"randomforestclassifier\")\n",
    "    new_pm[key] = values\n",
    "meta_params.update(new_pm)\n",
    "params.append(meta_params)\n",
    "\n",
    "print \"Num pipelines:\", num_pipeline\n",
    "print \"Selected filters:\",selected_filters\n",
    "print \"Params:\", params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 130 candidates, totalling 650 fits\n"
     ]
    }
   ],
   "source": [
    "cv_inner = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=24)\n",
    "\n",
    "sclf = StackingClassifier(classifiers=pipes, verbose=0, use_probas=True, average_probas=False,\n",
    "                            meta_classifier=RandomForestClassifier())    \n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, param_grid=params, n_jobs=-1,cv=cv_inner, \n",
    "                    scoring=\"recall\",refit=True, verbose=1,error_score = 0)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_outer = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=42)\n",
    "scorings = {'roc_auc': 'roc_auc',\n",
    "            'f1_weighted':'f1_weighted',\n",
    "            'precision_1':'precision',\n",
    "            'recall_1':'recall',\n",
    "            'precision_0' : metrics.make_scorer(MLpipeline.precision_0),\n",
    "            'recall_0' : metrics.make_scorer(MLpipeline.recall_0),\n",
    "            'spec': metrics.make_scorer(MLpipeline.specificity)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  0\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.814  (+/-0.001)\n",
      "Prec score [c=0,1]: 0.872 (+/- 0.000), 0.475  (+/- 0.050)\n",
      "Rec  score [c=0,1]: 0.996 (+/- 0.001), 0.025  (+/- 0.004)\n",
      "AUC score: 0.633  (+/-0.011)\n",
      "Sensitivity score: 0.025  (+/-0.004)\n",
      "Specificity score: 0.996  (+/-0.001)\n",
      "0 3 Visits_filter 8 8\n",
      "\n",
      "[['age' 0.21129500177683355]\n",
      " ['race_AfricanAmerican' 0.11039781722973173]\n",
      " ['race_Caucasian' 0.14114620559774096]\n",
      " ['number_inpatient' 0.33233721149153694]]\n",
      "\n",
      "Evaluation:  1\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.816  (+/-0.001)\n",
      "Prec score [c=0,1]: 0.872 (+/- 0.001), 0.494  (+/- 0.056)\n",
      "Rec  score [c=0,1]: 0.995 (+/- 0.001), 0.031  (+/- 0.005)\n",
      "AUC score: 0.679  (+/-0.011)\n",
      "Sensitivity score: 0.031  (+/-0.005)\n",
      "Specificity score: 0.995  (+/-0.001)\n",
      "1 6 extra_filter 65 65\n",
      "\n",
      "[['race_Caucasian' 0.11122938394634063]\n",
      " ['HbA1c' 0.23725184998204785]\n",
      " ['diabetesMed' 0.2042098916484064]\n",
      " ['diss_home' -0.23237138268749788]\n",
      " ['number_emergency' 0.1284097890780176]\n",
      " ['number_inpatient' 0.2587729271266445]\n",
      " ['number_diagnoses' 0.16591797439771072]\n",
      " ['metformin' -0.1061918274374678]\n",
      " ['ComplexHbA1c' -0.1519642117054967]\n",
      " ['add_in_out' 0.11636902878095864]\n",
      " ['div_em_time' -0.15069462802137193]\n",
      " ['Circulatory_3' 0.10328315755464185]]\n",
      "\n",
      "Evaluation:  2\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.810  (+/-0.001)\n",
      "Prec score [c=0,1]: 0.870 (+/- 0.000), 0.375  (+/- 0.107)\n",
      "Rec  score [c=0,1]: 0.997 (+/- 0.002), 0.010  (+/- 0.003)\n",
      "AUC score: 0.630  (+/-0.011)\n",
      "Sensitivity score: 0.010  (+/-0.003)\n",
      "Specificity score: 0.997  (+/-0.002)\n",
      "2 7 none_filter 17 17\n",
      "\n",
      "[['age' 0.2205740372996824]\n",
      " ['race_AfricanAmerican' 0.10044323636813225]\n",
      " ['race_Caucasian' 0.1353747144630919]\n",
      " ['add_in_out' 0.3689757339154169]\n",
      " ['add_procs_meds' 0.13570813345604452]\n",
      " ['div_visits_time' -0.14534959664602412]\n",
      " ['div_em_time' -0.13120882195812592]\n",
      " ['div_em_med' 0.1933643509285662]\n",
      " ['sum_ch_med' 0.18292519636097657]]\n",
      "\n",
      "Evaluation:  3\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.816  (+/-0.001)\n",
      "Prec score [c=0,1]: 0.872 (+/- 0.001), 0.529  (+/- 0.037)\n",
      "Rec  score [c=0,1]: 0.996 (+/- 0.000), 0.033  (+/- 0.005)\n",
      "AUC score: 0.679  (+/-0.011)\n",
      "Sensitivity score: 0.033  (+/-0.005)\n",
      "Specificity score: 0.996  (+/-0.000)\n",
      "3 8 no_diagnosis_filter 57 57\n",
      "\n",
      "[['age' 0.10181744515727185]\n",
      " ['race_Caucasian' 0.11602669442537829]\n",
      " ['HbA1c' 0.23712632718965737]\n",
      " ['diabetesMed' 0.20221763203551307]\n",
      " ['diss_home' -0.22592380949102964]\n",
      " ['number_emergency' 0.12900896811579818]\n",
      " ['number_inpatient' 0.2598956989209072]\n",
      " ['number_diagnoses' 0.13455883228318247]\n",
      " ['metformin' -0.10888817262779775]\n",
      " ['ComplexHbA1c' -0.14765002715894732]\n",
      " ['add_in_out' 0.11658643049246577]\n",
      " ['div_em_time' -0.1556885760332997]]\n",
      "\n",
      "Evaluation:  4\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.815  (+/-0.001)\n",
      "Prec score [c=0,1]: 0.872 (+/- 0.000), 0.504  (+/- 0.036)\n",
      "Rec  score [c=0,1]: 0.996 (+/- 0.001), 0.028  (+/- 0.003)\n",
      "AUC score: 0.681  (+/-0.010)\n",
      "Sensitivity score: 0.028  (+/-0.003)\n",
      "Specificity score: 0.996  (+/-0.001)\n",
      "4 9 selected_filter 17 17\n",
      "\n",
      "[['race_Caucasian' 0.10931612321466512]\n",
      " ['HbA1c' 0.129216555843595]\n",
      " ['diabetesMed' 0.2459209623581223]\n",
      " ['diss_home' -0.24201391354718338]\n",
      " ['adm_src_7' 0.12103160737683347]\n",
      " ['adm_1' -0.13727278659048875]\n",
      " ['number_inpatient' 0.28541831795828343]\n",
      " ['number_diagnoses' 0.14532992949030998]\n",
      " ['sum_ch_med' -0.1285653339724341]]\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(grid.best_estimator_.clfs_):\n",
    "    \n",
    "    \n",
    "    #Performance\n",
    "    cv_scores = cross_validate(c, X_train, y_train, \n",
    "                               cv=cv_outer, scoring=scorings, n_jobs=-1, return_train_score = False)\n",
    "    \n",
    "    for pre in [\"test\"]:\n",
    "        cv_f1_w_mean = np.mean(cv_scores[pre + \"_f1_weighted\"])\n",
    "        cv_f1_w_std = np.std(cv_scores[pre + \"_f1_weighted\"])\n",
    "        cv_p1_mean = np.mean(cv_scores[pre + \"_precision_1\"])\n",
    "        cv_p1_std = np.std(cv_scores[pre + \"_precision_1\"])\n",
    "        cv_r1_mean = np.mean(cv_scores[pre + \"_recall_1\"])\n",
    "        cv_r1_std = np.std(cv_scores[pre + \"_recall_1\"])                \n",
    "        cv_p0_mean = np.mean(cv_scores[pre + \"_precision_0\"])\n",
    "        cv_p0_std = np.std(cv_scores[pre + \"_precision_0\"])\n",
    "        cv_r0_mean = np.mean(cv_scores[pre + \"_recall_0\"])\n",
    "        cv_r0_std = np.std(cv_scores[pre + \"_recall_0\"])\n",
    "\n",
    "        cv_auc_mean = np.mean(cv_scores[pre + \"_roc_auc\"])\n",
    "        cv_auc_std = np.std(cv_scores[pre + \"_roc_auc\"])                \n",
    "        cv_spec_mean = np.mean(cv_scores[pre + \"_spec\"])\n",
    "        cv_spec_std = np.std(cv_scores[pre + \"_spec\"])\n",
    "        cv_sens_mean = cv_r1_mean\n",
    "        cv_sens_std = cv_r1_std\n",
    "\n",
    "        print \"\\nEvaluation: \", i\n",
    "        print \"*******************\"\n",
    "        print \"\\nf1-weighted score: %0.3f  (+/-%0.03f)\" % (cv_f1_w_mean,cv_f1_w_std)               \n",
    "        print \"Prec score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_p0_mean,cv_p0_std,cv_p1_mean,cv_p1_std)                \n",
    "        print \"Rec  score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_r0_mean,cv_r0_std,cv_r1_mean,cv_r1_std)\n",
    "        print \"AUC score: %0.3f  (+/-%0.03f)\" % (cv_auc_mean,cv_auc_std) \n",
    "        print \"Sensitivity score: %0.3f  (+/-%0.03f)\" % (cv_sens_mean,cv_sens_std) \n",
    "        print \"Specificity score: %0.3f  (+/-%0.03f)\" % (cv_spec_mean,cv_spec_std) \n",
    "        \n",
    "    #Feature importances\n",
    "    sel = selected_filters[i]\n",
    "    n,f = featFilters[sel]\n",
    "    f_cols = columns[:-1][f==1].values    \n",
    "    f_cols = f_cols[c.steps[-2][1].get_support()]\n",
    "    \n",
    "    print i, sel, n, len(f_cols), len(c.steps[-1][1].coef_[0])\n",
    "    \n",
    "    res = np.hstack((f_cols.reshape(-1,1),c.steps[-1][1].coef_.reshape(-1,1)))\n",
    "\n",
    "    print\n",
    "    print res[abs(res[:,1])>0.1,:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:  Train\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.689  (+/-0.006)\n",
      "Prec score [c=0,1]: 0.922 (+/- 0.002), 0.207  (+/- 0.002)\n",
      "Rec  score [c=0,1]: 0.627 (+/- 0.011), 0.647  (+/- 0.015)\n",
      "AUC score: 0.695  (+/-0.003)\n",
      "Sensitivity score: 0.647  (+/-0.015)\n",
      "Specificity score: 0.627  (+/-0.011)\n",
      "\n",
      "Evaluation:  CV\n",
      "*******************\n",
      "\n",
      "f1-weighted score: 0.692  (+/-0.007)\n",
      "Prec score [c=0,1]: 0.919 (+/- 0.004), 0.205  (+/- 0.005)\n",
      "Rec  score [c=0,1]: 0.632 (+/- 0.011), 0.632  (+/- 0.022)\n",
      "AUC score: 0.684  (+/-0.011)\n",
      "Sensitivity score: 0.632  (+/-0.022)\n",
      "Specificity score: 0.632  (+/-0.011)\n",
      "\n",
      "Summary:\n",
      "*********\n",
      "StackingClassifier(average_probas=False,\n",
      "          classifiers=[Pipeline(memory=None,\n",
      "     steps=[('FeatFilter', FeatFilter(ixCols=array([1, 1, ..., 0, 0]))), ('Imputer', TypeFeatImputer(allNameCols=['gender', 'age', 'race_AfricanAmerican', 'race_Caucasian', 'race_Other', 'number_outpatient', 'number_emergency', 'number_inpatient'],\n",
      "        dataCatC...ty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])],\n",
      "          meta_classifier=RandomForestClassifier(bootstrap=True, class_weight='balanced_subsample',\n",
      "            criterion='entropy', max_depth=2, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False),\n",
      "          use_features_in_secondary=False, use_probas=True, verbose=0)\n",
      "{'meta-randomforestclassifier__criterion': 'entropy', 'meta-randomforestclassifier__max_depth': 2, 'meta-randomforestclassifier__class_weight': 'balanced_subsample', 'meta-randomforestclassifier__n_estimators': 50}\n",
      "0.614100185529\n",
      "[0.7, 's', 'none', '[3, 6, 7, 8, 9]', 'recall', 'logReg', 0.68944103032134607, 0.0064812554159623496, 0.92181773345712581, 0.0018761119463037077, 0.2071758815631374, 0.0020153089022292379, 0.62666985875029924, 0.011095751121586998, 0.64718030182684672, 0.014606137587256689, 0.69470190496274564, 0.0027660914313627281, 0.64718030182684672, 0.014606137587256689, 0.62666985875029924, 0.011095751121586998, 0.69151146920554596, 0.0065359000800159278, 0.9193554643171552, 0.0039749325123802151, 0.20527157810677688, 0.0050884715827068912, 0.6319463836917063, 0.010533376489500644, 0.6315398886827458, 0.022189115232246481, 0.68354850558943592, 0.010570438490683254, 0.6315398886827458, 0.022189115232246481, 0.6319463836917063, 0.010533376489500644]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_validate(grid.best_estimator_, X_train, y_train, \n",
    "                           cv=cv_outer, scoring=scorings, n_jobs=-1, return_train_score = True)\n",
    "\n",
    "res = [ts_thr,sm_method[0],fs_methods[0],str(selected_filters),lms[0],cls_methods[0]]\n",
    "\n",
    "for pre in [\"train\",\"test\"]:\n",
    "    cv_f1_w_mean = np.mean(cv_scores[pre + \"_f1_weighted\"])\n",
    "    cv_f1_w_std = np.std(cv_scores[pre + \"_f1_weighted\"])\n",
    "    cv_p1_mean = np.mean(cv_scores[pre + \"_precision_1\"])\n",
    "    cv_p1_std = np.std(cv_scores[pre + \"_precision_1\"])\n",
    "    cv_r1_mean = np.mean(cv_scores[pre + \"_recall_1\"])\n",
    "    cv_r1_std = np.std(cv_scores[pre + \"_recall_1\"])                \n",
    "    cv_p0_mean = np.mean(cv_scores[pre + \"_precision_0\"])\n",
    "    cv_p0_std = np.std(cv_scores[pre + \"_precision_0\"])\n",
    "    cv_r0_mean = np.mean(cv_scores[pre + \"_recall_0\"])\n",
    "    cv_r0_std = np.std(cv_scores[pre + \"_recall_0\"])\n",
    "\n",
    "    cv_auc_mean = np.mean(cv_scores[pre + \"_roc_auc\"])\n",
    "    cv_auc_std = np.std(cv_scores[pre + \"_roc_auc\"])                \n",
    "    cv_spec_mean = np.mean(cv_scores[pre + \"_spec\"])\n",
    "    cv_spec_std = np.std(cv_scores[pre + \"_spec\"])\n",
    "    cv_sens_mean = cv_r1_mean\n",
    "    cv_sens_std = cv_r1_std\n",
    "\n",
    "    print \"\\nEvaluation: \", \"CV\" if pre == \"test\" else \"Train\"\n",
    "    print \"*******************\"\n",
    "    print \"\\nf1-weighted score: %0.3f  (+/-%0.03f)\" % (cv_f1_w_mean,cv_f1_w_std)               \n",
    "    print \"Prec score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_p0_mean,cv_p0_std,cv_p1_mean,cv_p1_std)                \n",
    "    print \"Rec  score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_r0_mean,cv_r0_std,cv_r1_mean,cv_r1_std)\n",
    "    print \"AUC score: %0.3f  (+/-%0.03f)\" % (cv_auc_mean,cv_auc_std) \n",
    "    print \"Sensitivity score: %0.3f  (+/-%0.03f)\" % (cv_sens_mean,cv_sens_std) \n",
    "    print \"Specificity score: %0.3f  (+/-%0.03f)\" % (cv_spec_mean,cv_spec_std)\n",
    "    \n",
    "    res.extend([cv_f1_w_mean,cv_f1_w_std,\n",
    "                cv_p0_mean,cv_p0_std,cv_p1_mean,cv_p1_std,\n",
    "                cv_r0_mean,cv_r0_std,cv_r1_mean,cv_r1_std,\n",
    "                cv_auc_mean,cv_auc_std,\n",
    "                cv_sens_mean,cv_sens_std,\n",
    "                cv_spec_mean,cv_spec_std\n",
    "               ])\n",
    "\n",
    "\n",
    "print \"\\nSummary:\"\n",
    "print \"*********\"\n",
    "print grid.best_estimator_\n",
    "print grid.best_params_\n",
    "print grid.best_score_\n",
    "\n",
    "print res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: test\n",
      "*******************\n",
      "\n",
      "TEST AUC: 0.616\n",
      "TEST sensitivity: 0.624880838894\n",
      "TEST Specificity: 0.606463195691\n",
      "\n",
      "TEST f1 (weighted): 0.672\n",
      "TEST f1 [c=0,1] [ 0.72936909  0.29497131]\n",
      "TEST Precision [c=0,1]: [ 0.91475303  0.19304962]\n",
      "TEST Recall [c=0,1]: [ 0.6064632   0.62488084]\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[16890 10960]\n",
      " [ 1574  2622]]\n"
     ]
    }
   ],
   "source": [
    "#Predict test data    \n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "evaluate(\"test\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_thr</th>\n",
       "      <th>sm</th>\n",
       "      <th>fs</th>\n",
       "      <th>pipes</th>\n",
       "      <th>metric</th>\n",
       "      <th>cls</th>\n",
       "      <th>tr_auc_mean</th>\n",
       "      <th>tr_sens_mean</th>\n",
       "      <th>tr_spec_mean</th>\n",
       "      <th>cv_auc_mean</th>\n",
       "      <th>cv_sens_mean</th>\n",
       "      <th>cv_spec_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[3, 6, 7, 8, 9]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.694701904963</td>\n",
       "      <td>0.647180301827</td>\n",
       "      <td>0.62666985875</td>\n",
       "      <td>0.683548505589</td>\n",
       "      <td>0.631539888683</td>\n",
       "      <td>0.631946383692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ts_thr sm    fs            pipes  metric     cls     tr_auc_mean  \\\n",
       "0    0.7  s  none  [3, 6, 7, 8, 9]  recall  logReg  0.694701904963   \n",
       "\n",
       "     tr_sens_mean   tr_spec_mean     cv_auc_mean    cv_sens_mean  \\\n",
       "0  0.647180301827  0.62666985875  0.683548505589  0.631539888683   \n",
       "\n",
       "     cv_spec_mean  \n",
       "0  0.631946383692  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "df_aux = pd.DataFrame(np.array(res).reshape(1,38),columns=[\"ts_thr\",\"sm\",\"fs\",\"pipes\",\"metric\",\"cls\",\n",
    "\"tr_f1_w_mean\",\"tr_f1_w_std\",\"tr_p0_mean\",\"tr_p0_std\",\"tr_p1_mean\",\"tr_p1_std\",\n",
    "\"tr_r0_mean\",\"tr_r0_std\",\"tr_r1_mean\",\"tr_r1_std\",\"tr_auc_mean\",\"tr_auc_std\",\n",
    "\"tr_sens_mean\",\"tr_sens_std\",\"tr_spec_mean\",\"tr_spec_std\",\n",
    "\"cv_f1_w_mean\",\"cv_f1_w_std\",\"cv_p0_mean\",\"cv_p0_std\",\"cv_p1_mean\",\"cv_p1_std\",\n",
    "\"cv_r0_mean\",\"cv_r0_std\",\"cv_r1_mean\",\"cv_r1_std\",\"cv_auc_mean\",\"cv_auc_std\",\n",
    "\"cv_sens_mean\",\"cv_sens_std\",\"cv_spec_mean\",\"cv_spec_std\"                                                       \n",
    " ])\n",
    "\n",
    "df_aux[[\"ts_thr\",\"sm\",\"fs\",\"pipes\",\"metric\",\"cls\",\"tr_auc_mean\",\n",
    "        \"tr_sens_mean\",\"tr_spec_mean\",\"cv_auc_mean\",\"cv_sens_mean\",\"cv_spec_mean\"]].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat to all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_thr</th>\n",
       "      <th>sm</th>\n",
       "      <th>fs</th>\n",
       "      <th>pipes</th>\n",
       "      <th>metric</th>\n",
       "      <th>cls</th>\n",
       "      <th>tr_auc_mean</th>\n",
       "      <th>tr_sens_mean</th>\n",
       "      <th>tr_spec_mean</th>\n",
       "      <th>cv_auc_mean</th>\n",
       "      <th>cv_sens_mean</th>\n",
       "      <th>cv_spec_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.634639352743</td>\n",
       "      <td>0.650059594756</td>\n",
       "      <td>0.553205243311</td>\n",
       "      <td>0.610293371503</td>\n",
       "      <td>0.616111111111</td>\n",
       "      <td>0.546962714705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.674739464227</td>\n",
       "      <td>0.625744934446</td>\n",
       "      <td>0.629520560244</td>\n",
       "      <td>0.64930223898</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.627398408044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.667385945455</td>\n",
       "      <td>0.6278515492</td>\n",
       "      <td>0.614814814815</td>\n",
       "      <td>0.648451189734</td>\n",
       "      <td>0.60031771247</td>\n",
       "      <td>0.614147217235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.684042584853</td>\n",
       "      <td>0.667892407218</td>\n",
       "      <td>0.59721965733</td>\n",
       "      <td>0.665527018156</td>\n",
       "      <td>0.638919777601</td>\n",
       "      <td>0.595332136445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>s</td>\n",
       "      <td>none</td>\n",
       "      <td>[3, 6, 7, 8, 9]</td>\n",
       "      <td>recall</td>\n",
       "      <td>logReg</td>\n",
       "      <td>0.694701904963</td>\n",
       "      <td>0.647180301827</td>\n",
       "      <td>0.62666985875</td>\n",
       "      <td>0.683548505589</td>\n",
       "      <td>0.631539888683</td>\n",
       "      <td>0.631946383692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ts_thr sm    fs                     pipes  metric     cls     tr_auc_mean  \\\n",
       "0    0.8  s  none                 [0, 1, 2]  recall  logReg  0.634639352743   \n",
       "0    0.8  s  none        [0, 1, 2, 3, 4, 5]  recall  logReg  0.674739464227   \n",
       "0    0.3  s  none        [0, 1, 2, 3, 4, 5]  recall  logReg  0.667385945455   \n",
       "0    0.3  s  none  [0, 1, 2, 3, 4, 5, 6, 7]  recall  logReg  0.684042584853   \n",
       "0    0.7  s  none           [3, 6, 7, 8, 9]  recall  logReg  0.694701904963   \n",
       "\n",
       "     tr_sens_mean    tr_spec_mean     cv_auc_mean    cv_sens_mean  \\\n",
       "0  0.650059594756  0.553205243311  0.610293371503  0.616111111111   \n",
       "0  0.625744934446  0.629520560244   0.64930223898            0.59   \n",
       "0    0.6278515492  0.614814814815  0.648451189734   0.60031771247   \n",
       "0  0.667892407218   0.59721965733  0.665527018156  0.638919777601   \n",
       "0  0.647180301827   0.62666985875  0.683548505589  0.631539888683   \n",
       "\n",
       "     cv_spec_mean  \n",
       "0  0.546962714705  \n",
       "0  0.627398408044  \n",
       "0  0.614147217235  \n",
       "0  0.595332136445  \n",
       "0  0.631946383692  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,df_aux])\n",
    "df[[\"ts_thr\",\"sm\",\"fs\",\"pipes\",\"metric\",\"cls\",\n",
    "    \"tr_auc_mean\",\"tr_sens_mean\",\"tr_spec_mean\",\"cv_auc_mean\",\"cv_sens_mean\",\"cv_spec_mean\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(clf, os.path.join('resources','results','ensemble_train_0_2_inner_logReg_outer_rf_3_pipes.pkl')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"res_ensemble_20171031-124424\"\n",
    "#filename = 'res_ensemble_' + time.strftime(\"%Y%m%d-%H%M%S\") + '.pkl'\n",
    "\n",
    "df.to_pickle(os.path.join('resources','results', filename + \".pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join('resources','results',\"res_ensemble_20171031-124424.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"tr_auc_mean\",\"tr_sens_mean\",\"tr_spec_mean\",\"cv_auc_mean\",\"cv_sens_mean\",\"cv_spec_mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
