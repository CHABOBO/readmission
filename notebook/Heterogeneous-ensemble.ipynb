{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO RE-RUN\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from operator import truediv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required domain methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"../src/\")\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter\n",
    "import MLpipeline as MLpipeline\n",
    "import readmision_methods as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeEncounter = \"last\" # ['first','last']\n",
    "typeHypothesis = \"early_readmission_vs_none\" # ['all_readmisssion_vs_none','early_readmission_vs_none']\n",
    "typeDataFeatures = \"extended_extra_diag_3\" # [\"reduced\",\"extended','extended_extra','extended_extra_diag_1','extended_extra_diag_3']\n",
    "typeDataExperiment = \"all\" #[\"all\", \"disease\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "tr_thrs = 0.2 # [0.1,0.2,0.4,0.6,1.0]\n",
    "ts_thr = 1 - tr_thrs\n",
    "\n",
    "fs_methods = [\"none\"] #[\"none\",\"combine_fs\",\"lasso_fs\",\"rfe_rf_fs\"]\n",
    "cls_methods = [\"rf\"] #[\"rf\",\"svmRBF\",\"logReg\",\"knn\",\"nn\",\"gbt\"]\n",
    "lms = [\"recall\",\"roc_auc\"] #[\"f1_weighted\",\"average_precision\",\"roc_auc\",\"recall\"]\n",
    "sm_types = [\"none\"] #[\"none\",\"after\"]tr_thrs\n",
    "sm_method = \"sm_smote\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(67182, 69)\n",
      "\n",
      "SHAPE FILTERED:\n",
      "(45779, 69)\n",
      "\n",
      "Rows by class type:\n",
      "[0 1] 39785 5994\n",
      "\n",
      "Train: (9155, 68) Test: (36624, 68)\n",
      "[['patient_filter', 5], ['admision_discharge_filter', 29], ['hospital_filter', 9], ['Visits_filter', 8], ['diagnosis_filter', 14], ['medicines_filter', 15], ['extra_filter', 68], ['none_filter', 17]]\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df_all = rm.load_data(typeEncounter, typeDataFeatures)\n",
    "print \"\\nSHAPE:\"\n",
    "print df_all.shape\n",
    "\n",
    "#Filter data by class\n",
    "df_all = rm.filter_data_by_class(df_all, typeHypothesis)\n",
    "print \"\\nSHAPE FILTERED:\"\n",
    "print df_all.shape\n",
    "\n",
    "print \"\\nRows by class type:\"\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)\n",
    "\n",
    "#Train & Test\n",
    "X_train, X_test, y_train, y_test = MLpipeline.train_test_partition(df_all,ts_thr)\n",
    "df_train = pd.DataFrame(np.hstack((X_train, y_train.reshape(-1,1))), columns=df_all.columns)\n",
    "df_test = pd.DataFrame(np.hstack((X_test, y_test.reshape(-1,1))), columns=df_all.columns)\n",
    "columns = df_all.columns\n",
    "\n",
    "print \"\\nTrain:\", X_train.shape, \"Test:\",  X_test.shape\n",
    "\n",
    "#Create filters\n",
    "featFilters = rm.create_filters(df_all)\n",
    "print [[f[0],np.sum(f[1])] for f in featFilters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(columns, X_train, X_test, y_train, y_test, cv_folds, cv_thr, fs_methods, sm_method, sm_types, \n",
    "                                            cls_methods, lms, featFilters):\n",
    "    #Train & test inner models\n",
    "    models, train_preds, test_preds = train_inner_models(columns, X_train, X_test, y_train, y_test, cv_folds, \n",
    "                                    cv_thr, fs_methods, sm_method, sm_types, cls_methods, lms, featFilters)\n",
    "    \n",
    "    #Train stack model\n",
    "    stacker = train_stacker(train_preds, y_train)\n",
    "    \n",
    "    #Test stack model\n",
    "    evaluate_stacker(stacker, test_preds, y_test)\n",
    "    \n",
    "    return models, stacker, train_preds, test_preds\n",
    "\n",
    "def train_inner_models(columns, X_train, X_test, y_train, y_test, cv_folds, cv_thr, fs_methods, \n",
    "                       sm_method, sm_types, cls_methods, lms, featFilters,verbose=True, save=False):\n",
    "    \n",
    "    models = []\n",
    "    cv_preds = []\n",
    "    ts_preds = []\n",
    "    for n,f in featFilters[:]:\n",
    "        \n",
    "        #Get categoric/numeric\n",
    "        f_cols = columns[:-1][f==1].values.tolist()\n",
    "        f_cols.append(\"readmitted\")       \n",
    "        catCols, reducedCols = rm.compute_type_features(f_cols)\n",
    "\n",
    "        #Get hyperparams\n",
    "        hyperparams = np.load(\"../src/default_hyperparams.npy\")\n",
    "\n",
    "        #Create pipeline\n",
    "        pipe = MLpipeline.create_pipelines(catCols, reducedCols, hyperparams, fs_methods, sm_method, sm_types, \n",
    "                                            cls_methods, lms, f)\n",
    "                 \n",
    "        #Prepare cv data\n",
    "        y_train = y_train.astype(int)\n",
    "        y_test = y_test.astype(int)        \n",
    "        cv_inner = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=24)\n",
    "        cv_outer = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=42)\n",
    "        \n",
    "        #Run pipeline        \n",
    "        res = MLpipeline.run_pipeline(n, pipe, X_train, X_test, y_train, y_test,  \n",
    "                                      cv_inner = cv_inner, \n",
    "                                      cv_outer = cv_outer,\n",
    "                                      verbose = verbose, save = save)[0]\n",
    "        \n",
    "        #Get predictions\n",
    "        tr_pred = res[-1].predict_proba(X_train).tolist()\n",
    "        ts_pred = res[-1].predict_proba(X_test).tolist()\n",
    "        \n",
    "        models.append(res)\n",
    "        cv_preds.append(tr_pred)\n",
    "        ts_preds.append(ts_pred)\n",
    "        \n",
    "    return models, cv_preds, ts_preds\n",
    "    \n",
    "def train_stacker(train_preds, y_train):\n",
    "        \n",
    "    #Prepare data stacker\n",
    "    train_preds = np.array(train_preds).astype(int).T\n",
    "    y_train = y_train.astype(int)    \n",
    "    \n",
    "    #Train stacker\n",
    "    cls = RandomForestClassifier(random_state=13,)\n",
    "    params = {'n_estimators':[10,50,100,150],\"class_weight\":[\"balanced\"],\"max_depth\":[3,4]}\n",
    "    \n",
    "    scorings = {\n",
    "        'recall_1':'recall',        \n",
    "        'roc_auc': 'roc_auc',\n",
    "        'f1_weighted':'f1_weighted',\n",
    "        'precision_1':'precision',\n",
    "        'precision_0' : metrics.make_scorer(MLpipeline.precision_0),\n",
    "        'recall_0' : metrics.make_scorer(MLpipeline.recall_0),\n",
    "        'spec': metrics.make_scorer(MLpipeline.specificity)\n",
    "       } \n",
    "    selected_metric = \"recall_1\"\n",
    "    grid_pipeline = GridSearchCV(cls, param_grid=params, verbose=True, \n",
    "                                 n_jobs=-1, cv=5, scoring= scorings, \n",
    "                                 refit=selected_metric, error_score = 0) \n",
    "    grid_pipeline.fit(train_preds, y_train)           \n",
    "    results = grid_pipeline.cv_results_\n",
    "    \n",
    "    print \"\\nSTACKER train-cv evaluation:\"\n",
    "    print \"*****************************\"\n",
    "    print \"Learning metric:\", selected_metric\n",
    "    print \"Best parameters:\", grid_pipeline.best_params_.values()\n",
    "    print \"Best score:\", grid_pipeline.best_score_\n",
    "    \n",
    "    for scorer in scorings:       \n",
    "        best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "        best_score = results['mean_test_%s' % scorer][best_index]\n",
    "        print \"BEST {}: {}\".format(scorer, best_score)\n",
    "    \n",
    "    return grid_pipeline \n",
    "\n",
    "def train_voting(train_preds, y_train):\n",
    "    \n",
    "    #Prepare data stacker\n",
    "    train_preds = np.array(train_preds).astype(int).T\n",
    "    y_train = y_train.astype(int)\n",
    "    \n",
    "    #Compute votes\n",
    "    y_pred = np.sum(train_preds, axis=1) > train_preds.shape[1]/2.0\n",
    "    \n",
    "    #Print results\n",
    "    evaluate(name, y_train, y_pred)\n",
    "    \n",
    "def evaluate_stacker(stacker, test_preds, y_test):\n",
    "    \n",
    "    #Prepare test data\n",
    "    test_preds = np.array(test_preds).astype(int).T   \n",
    "    y_test = y_test.astype(int)    \n",
    "\n",
    "    #Predict test data    \n",
    "    y_pred = stacker.best_estimator_.predict(test_preds)\n",
    "\n",
    "    #Evaluate results\n",
    "    evaluate(\"test\", y_test, y_pred)\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def evaluate(name, y_test, y_pred):\n",
    "\n",
    "    test_f1_w = metrics.f1_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "    test_p, test_r, test_f1, test_s = metrics.precision_recall_fscore_support(y_test, y_pred,labels=None,average=None, sample_weight=None)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    test_auc = metrics.auc(fpr, tpr)                \n",
    "    cm_test = metrics.confusion_matrix(y_test, y_pred)\n",
    "    tn = cm_test[0,0]\n",
    "    fp = cm_test[0,1]\n",
    "    fn = cm_test[1,0]\n",
    "    tp = cm_test[1,1]\n",
    "    test_sens = test_r[1]\n",
    "    test_spec = tn / float(tn+fp)\n",
    "\n",
    "    print \"\\nEvaluation:\", name\n",
    "    print \"*******************\"\n",
    "    print          \n",
    "    print \"TEST AUC: %0.3f\" % (test_auc)                \n",
    "    print \"TEST sensitivity:\", test_sens\n",
    "    print \"TEST Specificity:\", test_spec\n",
    "    print\n",
    "    print \"TEST f1 (weighted): %0.3f\" % (test_f1_w)\n",
    "    print \"TEST Precision [c=0,1]:\", test_p\n",
    "    print \"TEST Recall [c=0,1]:\", test_r  \n",
    "    \n",
    "    print \"Confussion matrix:\"\n",
    "    print \"         | PRED\"\n",
    "    print \"REAL-->  v \"\n",
    "    print cm_test\n",
    "    \n",
    "def test_ensemble(X_test, models, stacker):\n",
    "    \n",
    "    test_preds = []\n",
    "    for m in models:\n",
    "        test_preds.append(m[-1].predict(X_test.tolist()))\n",
    "    \n",
    "    test_preds = np.array(test_preds).astype(int).T\n",
    "    test_preds = test_preds.astype(int)\n",
    "    print test_preds.shape\n",
    "    \n",
    "    y_pred = stacker.predict(test_preds)\n",
    "    y_test = df_test.iloc[:,-1].values.astype(int)\n",
    "    print type(y_pred), np.unique(y_pred)\n",
    "    print type(y_test), np.unique(y_test)\n",
    "    \n",
    "    #Evaluate results\n",
    "    evaluate(\"test\", y_test, y_pred.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataSet:\n",
      "**********\n",
      "**********\n",
      "SIZE: 1.0\n",
      "NAME: patient_filter\n",
      "ALL TRAIN: (9155, 68)\n",
      "TRAIN: [0's: 7956 1's: 1199 ]\n",
      "ALL TEST: (36624, 68)\n",
      "TEST: [0's: 31829 1's: 4795 ]\n",
      "\n",
      "Num experiment: 0 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: recall\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN f1 (weighted): 0.530\n",
      "TRAIN Precision [c=0,1]: [ 0.89699571  0.15017505]\n",
      "TRAIN Recall [c=0,1]: [ 0.42031171  0.67973311]\n",
      "TRAIN AUC: 0.550\n",
      "TRAIN sensitivity: 0.679733110926\n",
      "TRAIN Specificity:  0.420311714429\n",
      "\n",
      "CV INNER metric: recall\n",
      "CV INNER selected params ['gini', 2, 'balanced_subsample', 50]\n",
      "CV INNER score: 0.653333333333\n",
      "\n",
      "CV OUTER f1-weighted score: 0.533  (+/-0.042)\n",
      "CV OUTER prec score [c=0,1]: 0.895 (+/- 0.008), 0.149  (+/- 0.002)\n",
      "CV OUTER rec  score [c=0,1]: 0.428 (+/- 0.055), 0.663  (+/- 0.068)\n",
      "CV OUTER AUC score: 0.566  (+/-0.012)\n",
      "CV OUTER sensitivity score: 0.663  (+/-0.068)\n",
      "CV OUTER Specificity score: 0.428  (+/-0.055)\n",
      "Selected params (bests from CV) ['gini', 2, 'balanced_subsample', 50]\n",
      "\n",
      "TEST f1 (weighted): 0.528\n",
      "TEST Precision [c=0,1]: [ 0.89780235  0.15048187]\n",
      "TEST Recall [c=0,1]: [ 0.41842345  0.68383733]\n",
      "TEST AUC: 0.551\n",
      "TEST sensitivity: 0.683837330553\n",
      "TEST Specificity: 0.418423450313\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[13318 18511]\n",
      " [ 1516  3279]]\n",
      "\n",
      "Total time: 184.61264205\n",
      "\n",
      "Num experiment: 1 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: roc_auc\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN f1 (weighted): 0.539\n",
      "TRAIN Precision [c=0,1]: [ 0.89557292  0.15014111]\n",
      "TRAIN Recall [c=0,1]: [ 0.43225239  0.66555463]\n",
      "TRAIN AUC: 0.549\n",
      "TRAIN sensitivity: 0.665554628857\n",
      "TRAIN Specificity:  0.432252388135\n",
      "\n",
      "CV INNER metric: roc_auc\n",
      "CV INNER selected params ['entropy', 2, 'balanced_subsample', 500]\n",
      "CV INNER score: 0.558709910162\n",
      "\n",
      "CV OUTER f1-weighted score: 0.543  (+/-0.041)\n",
      "CV OUTER prec score [c=0,1]: 0.893 (+/- 0.005), 0.149  (+/- 0.002)\n",
      "CV OUTER rec  score [c=0,1]: 0.441 (+/- 0.054), 0.649  (+/- 0.061)\n",
      "CV OUTER AUC score: 0.568  (+/-0.011)\n",
      "CV OUTER sensitivity score: 0.649  (+/-0.061)\n",
      "CV OUTER Specificity score: 0.441  (+/-0.054)\n",
      "Selected params (bests from CV) ['entropy', 2, 'balanced_subsample', 500]\n",
      "\n",
      "TEST f1 (weighted): 0.540\n",
      "TEST Precision [c=0,1]: [ 0.89717925  0.15128543]\n",
      "TEST Recall [c=0,1]: [ 0.43369254  0.67007299]\n",
      "TEST AUC: 0.552\n",
      "TEST sensitivity: 0.670072992701\n",
      "TEST Specificity: 0.433692544535\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[13804 18025]\n",
      " [ 1582  3213]]\n",
      "\n",
      "Total time: 192.325235128\n",
      "\n",
      "DataSet:\n",
      "**********\n",
      "**********\n",
      "SIZE: 1.0\n",
      "NAME: admision_discharge_filter\n",
      "ALL TRAIN: (9155, 68)\n",
      "TRAIN: [0's: 7956 1's: 1199 ]\n",
      "ALL TEST: (36624, 68)\n",
      "TEST: [0's: 31829 1's: 4795 ]\n",
      "\n",
      "Num experiment: 0 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: recall\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  4.2min finished\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN f1 (weighted): 0.711\n",
      "TRAIN Precision [c=0,1]: [ 0.89595943  0.18507561]\n",
      "TRAIN Recall [c=0,1]: [ 0.68841126  0.46955796]\n",
      "TRAIN AUC: 0.579\n",
      "TRAIN sensitivity: 0.469557964971\n",
      "TRAIN Specificity:  0.688411261941\n",
      "\n",
      "CV INNER metric: recall\n",
      "CV INNER selected params ['entropy', 2, 'balanced_subsample', 50]\n",
      "CV INNER score: 0.513888888889\n",
      "\n",
      "CV OUTER f1-weighted score: 0.677  (+/-0.031)\n",
      "CV OUTER prec score [c=0,1]: 0.897 (+/- 0.003), 0.176  (+/- 0.009)\n",
      "CV OUTER rec  score [c=0,1]: 0.630 (+/- 0.051), 0.522  (+/- 0.045)\n",
      "CV OUTER AUC score: 0.602  (+/-0.011)\n",
      "CV OUTER sensitivity score: 0.522  (+/-0.045)\n",
      "CV OUTER Specificity score: 0.630  (+/-0.051)\n",
      "Selected params (bests from CV) ['entropy', 2, 'balanced_subsample', 50]\n",
      "\n",
      "TEST f1 (weighted): 0.714\n",
      "TEST Precision [c=0,1]: [ 0.89960169  0.19150843]\n",
      "TEST Recall [c=0,1]: [ 0.68830312  0.49009385]\n",
      "TEST AUC: 0.589\n",
      "TEST sensitivity: 0.490093847758\n",
      "TEST Specificity: 0.688303119796\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[21908  9921]\n",
      " [ 2445  2350]]\n",
      "\n",
      "Total time: 285.66348505\n",
      "\n",
      "Num experiment: 1 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: roc_auc\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  3.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b93b1c4e2cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m models, train_preds, test_preds = train_inner_models(columns, X_train, X_test, y_train, y_test, \n\u001b[1;32m      3\u001b[0m                                     \u001b[0mcv_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_thr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_methods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_methods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                                               featFilters)  \n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-208ba92a2d7e>\u001b[0m in \u001b[0;36mtrain_inner_models\u001b[0;34m(columns, X_train, X_test, y_train, y_test, cv_folds, cv_thr, fs_methods, sm_method, sm_types, cls_methods, lms, featFilters, verbose, save)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                       \u001b[0mcv_inner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_inner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                       \u001b[0mcv_outer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_outer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                                       verbose = verbose, save = save)[0]\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/healthforecast/readmission/src/MLpipeline.py\u001b[0m in \u001b[0;36mrun_pipeline\u001b[0;34m(name, pipeline, X_train, X_test, y_train, y_test, tr_thr, ts_thr, cv_inner, cv_outer, verbose, save)\u001b[0m\n\u001b[1;32m    235\u001b[0m         grid_pipeline = GridSearchCV(pipeline_cls, param_grid=pipeline_params, verbose=verbose, \n\u001b[1;32m    236\u001b[0m                                      n_jobs=-1, cv=cv_inner, scoring= lm, error_score = 0) \n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mgrid_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ilmira/.conda/envs/readmision/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train ensemble\n",
    "models, train_preds, test_preds = train_inner_models(columns, X_train, X_test, y_train, y_test, \n",
    "                                    cv_folds, cv_thr, fs_methods, sm_method, sm_types, cls_methods, lms, \n",
    "                                                              featFilters)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: CV\n",
      "*******************\n",
      "\n",
      "TEST AUC: 0.910\n",
      "TEST sensitivity: 0.850945494994\n",
      "TEST Specificity: 0.969501466276\n",
      "\n",
      "TEST f1 (weighted): 0.954\n",
      "TEST Precision [c=0,1]: [ 0.97736295  0.80781415]\n",
      "TEST Recall [c=0,1]: [ 0.96950147  0.85094549]\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[11571   364]\n",
      " [  268  1530]]\n",
      "\n",
      "Evaluation: CV\n",
      "*******************\n",
      "\n",
      "TEST AUC: 0.523\n",
      "TEST sensitivity: 0.0972354623451\n",
      "TEST Specificity: 0.949228007181\n",
      "\n",
      "TEST f1 (weighted): 0.809\n",
      "TEST Precision [c=0,1]: [ 0.87466914  0.22392975]\n",
      "TEST Recall [c=0,1]: [ 0.94922801  0.09723546]\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[26436  1414]\n",
      " [ 3788   408]]\n"
     ]
    }
   ],
   "source": [
    "train_voting(train_preds, y_train)\n",
    "train_voting(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:   26.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STACKER train-cv evaluation:\n",
      "*****************************\n",
      "Learning metric: recall_1\n",
      "Best parameters: [150, 2, 'balanced']\n",
      "Best score: 0.813688292549\n",
      "BEST f1_weighted: 0.792214881633\n",
      "BEST precision_1: 0.322098029974\n",
      "BEST precision_0: 0.960803353265\n",
      "BEST recall_0: 0.752743163799\n",
      "BEST recall_1: 0.813688292549\n",
      "BEST spec: 0.752743163799\n",
      "BEST roc_auc: 0.828442603914\n"
     ]
    }
   ],
   "source": [
    "#print len(train_preds[:6])\n",
    "stacker = train_stacker(train_preds[:6], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01026769,  0.06199544,  0.276107  ,  0.05591211,  0.13716804,\n",
       "        0.45854971])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: test\n",
      "*******************\n",
      "\n",
      "TEST AUC: 0.563\n",
      "TEST sensitivity: 0.482125834128\n",
      "TEST Specificity: 0.644272890485\n",
      "\n",
      "TEST f1 (weighted): 0.683\n",
      "TEST Precision [c=0,1]: [ 0.89197654  0.16957251]\n",
      "TEST Recall [c=0,1]: [ 0.64427289  0.48212583]\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[17943  9907]\n",
      " [ 2173  2023]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_stacker(stacker, test_preds[:6], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>size_tr</th>\n",
       "      <th>cls</th>\n",
       "      <th>metric</th>\n",
       "      <th>params</th>\n",
       "      <th>tr_sens</th>\n",
       "      <th>tr_spec</th>\n",
       "      <th>tr_auc</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>cv_sens_mean</th>\n",
       "      <th>cv_spec_mean</th>\n",
       "      <th>cv_auc_mean</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>test_sens</th>\n",
       "      <th>test_spec</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[entropy, 4, 400]</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>diagnosis_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[gini, 8, 200]</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admision_discharge_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[entropy, 8, 200]</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visits_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[entropy, 4, 200]</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hospital_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[gini, 8, 400]</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[entropy, 4, 500]</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>medicines_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[gini, 12, 400]</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>extra_filter</td>\n",
       "      <td>1.00</td>\n",
       "      <td>rf</td>\n",
       "      <td>precision</td>\n",
       "      <td>[gini, None, 350]</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name size_tr cls     metric             params  \\\n",
       "0             patient_filter    1.00  rf  precision  [entropy, 4, 400]   \n",
       "4           diagnosis_filter    1.00  rf  precision     [gini, 8, 200]   \n",
       "1  admision_discharge_filter    1.00  rf  precision  [entropy, 8, 200]   \n",
       "3              Visits_filter    1.00  rf  precision  [entropy, 4, 200]   \n",
       "2            hospital_filter    1.00  rf  precision     [gini, 8, 400]   \n",
       "7                none_filter    1.00  rf  precision  [entropy, 4, 500]   \n",
       "5           medicines_filter    1.00  rf  precision    [gini, 12, 400]   \n",
       "6               extra_filter    1.00  rf  precision  [gini, None, 350]   \n",
       "\n",
       "  tr_sens tr_spec tr_auc tr_f1 cv_sens_mean cv_spec_mean cv_auc_mean  \\\n",
       "0    0.71    0.41   0.56  0.52         0.64         0.46        0.56   \n",
       "4    0.68    0.60   0.64  0.67         0.53         0.61        0.60   \n",
       "1    0.63    0.63   0.63  0.69         0.50         0.66        0.62   \n",
       "3    0.41    0.78   0.60  0.76         0.44         0.74        0.63   \n",
       "2    0.68    0.69   0.69  0.74         0.42         0.69        0.58   \n",
       "7    0.47    0.75   0.61  0.75         0.42         0.76        0.64   \n",
       "5    0.76    0.74   0.75  0.78         0.37         0.74        0.58   \n",
       "6    1.00    1.00   1.00  1.00         0.01         1.00        0.66   \n",
       "\n",
       "  cv_f1_mean test_sens test_spec test_auc test_f1  \n",
       "0       0.55      0.70      0.40     0.55    0.51  \n",
       "4       0.66      0.53      0.59     0.56    0.65  \n",
       "1       0.70      0.54      0.63     0.58    0.68  \n",
       "3       0.74      0.37      0.78     0.58    0.76  \n",
       "2       0.71      0.45      0.67     0.56    0.70  \n",
       "7       0.75      0.42      0.74     0.58    0.74  \n",
       "5       0.73      0.38      0.71     0.55    0.72  \n",
       "6       0.81      0.01      1.00     0.50    0.81  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(np.array(models).reshape(-1,35), columns=\n",
    "                              [\"exp\", \"name\",\n",
    "                               \"size_tr\",\"fs\",\"sm\",\"cls\",\"metric\",\"params\",\n",
    "                               \"tr_sens\",\"tr_spec\",\"tr_auc\",\n",
    "                               \"tr_prec\",\"tr_rec\",\"tr_f1\",\n",
    "                               \"cv_sens_mean\",\"cv_sens_std\",\"cv_spec_mean\",\"cv_spec_std\",\"cv_auc_mean\",\"cv_auc_std\",\n",
    "                               \"cv_prec_mean\",\"cv_prec_std\",\"cv_rec_mean\",\"cv_rec_std\",\n",
    "                               \"cv_f1_mean\",\"cv_f1_std\",\n",
    "                               \"test_sens\",\"test_spec\",\"test_auc\",\n",
    "                               \"test_rec\",\"test_prec\",\"test_f1\",\n",
    "                               \"cm_test\",\n",
    "                               \"time\",\"pipeline\"])\n",
    "res[[\"name\",\"size_tr\",\"cls\",\"metric\",\"params\",\"tr_sens\",\"tr_spec\",\"tr_auc\",\n",
    "    \"tr_f1\",\"cv_sens_mean\",\"cv_spec_mean\",\"cv_auc_mean\",\"cv_f1_mean\",\n",
    "    \"test_sens\",\"test_spec\",\"test_auc\",\"test_f1\"]].sort_values(\"cv_sens_mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
