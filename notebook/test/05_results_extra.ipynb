{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from operator import truediv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../src/\")\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter\n",
    "import MLpipeline as MLpipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Local methods\n",
    "\n",
    "def load_data(typeEncounter, typeDiagnosis, typeDataFeatures):\n",
    "\n",
    "    if typeDataFeatures == \"non_extended\":\n",
    "        df_all=pd.read_pickle(os.path.join('resources','prepared_clean_data_' + typeEncounter + \"_\" +  typeDiagnosis + '.pkl'))\n",
    "    else:\n",
    "        df_all=pd.read_pickle(os.path.join('resources','prepared_clean_data_' + typeEncounter + \"_\" +  typeDiagnosis + '_' + typeDataFeatures + '.pkl'))\n",
    "\n",
    "\n",
    "    return df_all\n",
    "\n",
    "def get_columns(df_all, typeDiagnosis):\n",
    "\n",
    "    colsDiseases = []\n",
    "    if typeDiagnosis == \"diag_1\":\n",
    "        colsDiseases = [u'Diabetis_1', u'Circulatory_1', u'Digestive_1', u'Genitourinary_1', u'Poisoning_1', u'Muscoskeletal_1',\n",
    "               u'Neoplasms_1', u'Respiratory_1']\n",
    "\n",
    "    if typeDiagnosis == \"diag_3\":\n",
    "        colsDiseases = [u'Diabetis_3', u'Circulatory_3', u'Digestive_3', u'Genitourinary_3', u'Poisoning_3', u'Muscoskeletal_3',\n",
    "               u'Neoplasms_3', u'Respiratory_3']\n",
    "    \n",
    "    colsNonDiseases = [c for c in df_all.columns if c not in colsDiseases]\n",
    "    \n",
    "    return colsDiseases, colsNonDiseases\n",
    "\n",
    "def filter_data_by_class(df_all, typeHypothesis):\n",
    "    \n",
    "    # Readmitted none vs readmitted\n",
    "    if typeHypothesis == \"all_readmisssion_vs_none\":\n",
    "        df_all[\"readmitted\"][df_all[\"readmitted\"].values > 0] = 1\n",
    "\n",
    "    # Readmitted none vs early readmitted            \n",
    "    if typeHypothesis == \"early_readmission_vs_none\":\n",
    "        df_all= df_all[df_all[\"readmitted\"].isin([0,1])]\n",
    "        \n",
    "    return df_all\n",
    "\n",
    "def compute_type_features(df_all, typeDataFeatures):\n",
    "\n",
    "    numCols = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', \n",
    "                'number_emergency', 'number_inpatient', 'number_diagnoses',\n",
    "                'add_in_out', 'add_procs_meds', 'div_visits_time', 'div_em_time', 'div_visit_med', 'div_em_med',\n",
    "                'number_treatment','number_treatment_0','number_treatment_1','number_treatment_2','number_treatment_3']\n",
    "\n",
    "    catCols = []\n",
    "    cols = df_all.columns\n",
    "    reducedCols = cols[:-1]\n",
    "\n",
    "    for i in range(len(cols)-1):\n",
    "        if cols[i] not in numCols:\n",
    "            catCols.append(1)\n",
    "        else:\n",
    "            catCols.append(0)\n",
    "    catCols = np.array(catCols)\n",
    "    \n",
    "    return catCols, reducedCols\n",
    "\n",
    "def get_diseases(colsDiseases, typeDisease):\n",
    "    if typeDisease == \"subset\":\n",
    "        return [\"subset\"]\n",
    "    else:\n",
    "        if typeDisease in colsDiseases:\n",
    "            return [typeDisease]\n",
    "        else:\n",
    "            return colsDiseases\n",
    "\n",
    "def filter_data_by_diseases(df_all, disease, typeDataExperiment, colsNonDiseases):\n",
    "    if disease == \"subset\":\n",
    "        df_all_filtered = df_all.copy()\n",
    "    else:\n",
    "        cols_filtered = colsNonDiseases[:]\n",
    "        cols_filtered.insert(-1, disease)\n",
    "        df_all_filtered = df_all[cols_filtered].copy()    \n",
    "    \n",
    "    if typeDataExperiment == \"disease\" and disease != \"subset\":\n",
    "        df_all_filtered = df_all_filtered[df_all_filtered[disease] == 1]\n",
    "        df_all_filtered = df_all_filtered[[c for c in df_all_filtered.columns if c != disease]]\n",
    "    \n",
    "    return df_all_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic methods\n",
    "def train_test_partition(df_all, ts_thr=0.30):\n",
    "    y = df_all.readmitted\n",
    "    y = y.values\n",
    "\n",
    "    X = df_all.iloc[:,:-1].values\n",
    "    sss = StratifiedShuffleSplit(y, 1, test_size=ts_thr, random_state=32) #random_state=42\n",
    "    for train_index, test_index in sss:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_partition(X_train, y_train, tr_thr=0.10):\n",
    "    X_train_aux = []\n",
    "    y_train_aux = []\n",
    "    if tr_thr >= 1.0:\n",
    "            X_train_aux = X_train\n",
    "            y_train_aux = y_train\n",
    "    else:\n",
    "        sss = StratifiedShuffleSplit(y_train, 1, test_size=1-tr_thr, random_state=32) #random_state=42\n",
    "        for train_index, test_index in sss:\n",
    "            X_train_aux = X_train[train_index]\n",
    "            y_train_aux = y_train[train_index]\n",
    "\n",
    "    return X_train_aux, y_train_aux\n",
    "\n",
    "def create_pipelines(catCols,reducedCols, hyperparams, fs_methods, sm_method, sm_types, cls_methods, lms):\n",
    "    \n",
    "    basePipeline = Pipeline([\n",
    "            (\"Imputer\", TypeFeatImputer(catCols, reducedCols)),\n",
    "            (\"Scaler\", StandardScaler()),\n",
    "            (\"Variance\", VarianceThreshold(threshold=0.0))\n",
    "        ])\n",
    "\n",
    "    pipeline = [] \n",
    "\n",
    "    for fs_method in fs_methods:\n",
    "        for sm_type in sm_types:\n",
    "            for cls_method in cls_methods:\n",
    "                for lm in lms:\n",
    "                    if not (fs_method == \"rfe_rf_fs\" and cls_method == \"rf\") and not(fs_method == \"lasso_fs\" and cls_method == \"logReg\"):\n",
    "                        params = {}   \n",
    "                        pipe = Pipeline(list(basePipeline.steps))\n",
    "\n",
    "                        if fs_method == \"combine_fs\":\n",
    "                            pipe.steps.insert(1,(fs_method, UnivCombineFilter(catCols,np.array(reducedCols))))\n",
    "                            pm = hyperparams[hyperparams[:,1] == fs_method,2][0]\n",
    "                            params.update(pm)                            \n",
    "\n",
    "\n",
    "                        if fs_method == \"rfe_rf_fs\":\n",
    "                            pipe.steps.append((fs_method, RFE(estimator=RandomForestClassifier(class_weight='balanced',\n",
    "                                                                                               n_estimators=100,\n",
    "                                                                                               random_state=33))))\n",
    "                            pm = hyperparams[hyperparams[:,1] == fs_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "                        if fs_method == 'lasso_fs':\n",
    "                            pipe.steps.append((fs_method, SelectFromModel(\n",
    "                                        LogisticRegression(n_jobs=-1, penalty=\"l1\", dual=False, random_state=42))))\n",
    "                            pm = hyperparams[hyperparams[:,1] == fs_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "                        #Add classifiers\n",
    "                        if cls_method == \"knn\":\n",
    "                            pipe.steps.append((cls_method, KNeighborsClassifier()))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "                        if cls_method == \"logReg\":\n",
    "                            pipe.steps.append((cls_method, LogisticRegression(random_state=42)))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "                        if cls_method == \"svmRBF\":\n",
    "                            pipe.steps.append((cls_method, SVC(random_state=42,probability=True)))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "\n",
    "                        if cls_method == \"rf\":\n",
    "                            pipe.steps.append((cls_method, RandomForestClassifier(n_jobs=-1,class_weight='balanced',random_state=42)))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "                        if cls_method == \"gbt\":\n",
    "                            pipe.steps.append((cls_method, GradientBoostingClassifier(random_state=42,subsample=0.1,loss=\"deviance\")))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "\n",
    "                        if cls_method == \"nb\":\n",
    "                            pipe.steps.append((cls_method, GaussianNB()))\n",
    "                            params.update({}) \n",
    "                            \n",
    "                        if cls_method == \"nn\":\n",
    "                            pipe.steps.append((cls_method, MLPClassifier(\n",
    "                                        activation='logistic',\n",
    "                                        solver='lbfgs', \n",
    "                                        hidden_layer_sizes=(5, 2), \n",
    "                                        random_state=13)))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "                            \n",
    "\n",
    "                        #Add sampling\n",
    "                        pipe_imb = make_pipeline(*[p[1] for p in pipe.steps])\n",
    "                        stps = len(pipe_imb.steps)        \n",
    "                        for s in range(stps):\n",
    "                            pipe_imb.steps.remove(pipe_imb.steps[0])\n",
    "                        for s in range(stps):\n",
    "                            pipe_imb.steps.append(pipe.steps[s])\n",
    "\n",
    "                        if sm_type == \"after\":                    \n",
    "                            pipe_imb.steps.insert(stps - 1, \n",
    "                                                  (sm_method, SMOTE(ratio='auto', kind='regular', random_state=32)))\n",
    "                            pm = hyperparams[hyperparams[:,1] == cls_method,2][0]\n",
    "                            params.update(pm) \n",
    "\n",
    "                        pipeline.append([fs_method,sm_type,cls_method,lm,pipe_imb,params])\n",
    "\n",
    "    pipelines = pd.DataFrame(pipeline, columns=[\"fs\",\"sm\",\"cls\",\"metric\",\"pipe\",\"pipe_params\"])\n",
    "    pipelines.sort_values(\"fs\", inplace=True)\n",
    "\n",
    "    return pipelines\n",
    "\n",
    "def precision_0(ground_truth, predictions):\n",
    "    prec = metrics.precision_score(ground_truth, predictions,pos_label=0)\n",
    "    return prec\n",
    "\n",
    "def recall_0(ground_truth, predictions):\n",
    "    rec = metrics.recall_score(ground_truth, predictions,pos_label=0)\n",
    "    return rec\n",
    "\n",
    "def specificity(ground_truth, predictions):\n",
    "    cm_train = metrics.confusion_matrix(ground_truth, predictions)\n",
    "    tn = cm_train[0,0]\n",
    "    fp = cm_train[0,1]\n",
    "    fn = cm_train[1,0]\n",
    "    tp = cm_train[1,1]\n",
    "    train_spec = tn / float(tn+fp)\n",
    "    return train_spec\n",
    "\n",
    "# One Experiment One file \n",
    "def run(name,df_all, catCols, reducedCols, hyperparams, \n",
    "        ts_thr, tr_thrs, fs_methods, sm_method, sm_types, cls_methods, lms, cv_folds, cv_thr, \n",
    "        verbose=True, save=False):\n",
    "\n",
    "    results = []\n",
    "    for tr_thr in tr_thrs:\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_partition(df_all, ts_thr)\n",
    "            X_train, y_train = train_partition(X_train, y_train, tr_thr)\n",
    "            \n",
    "            pipeline = create_pipelines(catCols, reducedCols, hyperparams, fs_methods, sm_method, sm_types, cls_methods, lms)\n",
    "\n",
    "            print \"\\nDataSet:\"\n",
    "            print \"**********\"\n",
    "            print \"**********\"\n",
    "            print \"SIZE:\", tr_thr\n",
    "            print \"NAME:\", name\n",
    "\n",
    "            print df_all.shape\n",
    "            print \"ALL TRAIN:\", X_train.shape\n",
    "            print \"TRAIN:\", \"[0's:\", np.sum(y_train==0), \"1's:\", np.sum(y_train==1), \"]\"\n",
    "            print \"ALL TEST:\", X_test.shape\n",
    "            print \"TEST:\", \"[0's:\", np.sum(y_test==0), \"1's:\", np.sum(y_test==1), \"]\"\n",
    "\n",
    "            for num_exp in range(pipeline.shape[0]):\n",
    "\n",
    "                # Run experiment\n",
    "                start = time.time()\n",
    "\n",
    "                #Prepare pipe_cls      \n",
    "                pipeline_cls = pipeline[\"pipe\"].iloc[num_exp]\n",
    "                pipeline_params = pipeline[\"pipe_params\"].iloc[num_exp]\n",
    "                fs = pipeline[\"fs\"].iloc[num_exp]\n",
    "                sm = pipeline[\"sm\"].iloc[num_exp]\n",
    "                cls = pipeline[\"cls\"].iloc[num_exp]\n",
    "                lm = pipeline[\"metric\"].iloc[num_exp]\n",
    "\n",
    "                print \"\\nNum experiment:\", str(num_exp), \"/\", str(pipeline.shape[0] - 1)\n",
    "                print \"****************\"\n",
    "\n",
    "                print \"FS:\",fs\n",
    "                print \"SM:\",sm\n",
    "                print \"CLS:\",cls\n",
    "                print \"METRIC:\",lm\n",
    "\n",
    "                #Prepare cv\n",
    "                cv_inner = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=24)\n",
    "                cv_outer = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=42)\n",
    "\n",
    "                #Fit pipeline with CV                        \n",
    "                grid_pipeline = GridSearchCV(pipeline_cls, param_grid=pipeline_params, verbose=verbose, \n",
    "                                             n_jobs=-1, cv=cv_inner, scoring= lm, error_score = 0) \n",
    "                grid_pipeline.fit(X_train, y_train)\n",
    "                \n",
    "                \n",
    "                # Compute Train scores (with best CV params)\n",
    "                y_pred = grid_pipeline.best_estimator_.predict(X_train)  \n",
    "                train_f1_w = metrics.f1_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "                train_p, train_r, train_f1, train_s = metrics.precision_recall_fscore_support(y_train, y_pred,labels=None,average=None, sample_weight=None)\n",
    "                fpr, tpr, _ = metrics.roc_curve(y_train, y_pred)\n",
    "                train_auc = metrics.auc(fpr, tpr)                \n",
    "                cm_train = metrics.confusion_matrix(y_train, y_pred)\n",
    "                tn = cm_train[0,0]\n",
    "                fp = cm_train[0,1]\n",
    "                fn = cm_train[1,0]\n",
    "                tp = cm_train[1,1]\n",
    "                train_sens = train_r[1]\n",
    "                train_spec = tn / float(tn+fp)                \n",
    "                print \"\\nTRAIN f1 (weighted): %0.3f\" % (train_f1_w)\n",
    "                print \"TRAIN Precision [c=0,1]:\", train_p\n",
    "                print \"TRAIN Recall [c=0,1]:\", train_r\n",
    "                print \"TRAIN AUC: %0.3f\" % (train_auc)                 \n",
    "                print \"TRAIN Sensibility:\", train_sens\n",
    "                print \"TRAIN Specificity: \", train_spec\n",
    "                \n",
    "                # Compute evaluation scores\n",
    "                print \"\\nCV INNER metric: {}\".format(lm)\n",
    "                print \"CV INNER selected params {}\".format(grid_pipeline.best_params_.values())\n",
    "                print \"CV INNER score: {}\".format(grid_pipeline.best_score_)\n",
    "\n",
    "                scorings = {'roc_auc': 'roc_auc',\n",
    "                            'f1_weighted':'f1_weighted',\n",
    "                            'f1':'f1',\n",
    "                            'precision_1':'precision',\n",
    "                            'recall_1':'recall',\n",
    "                            'precision_0' : metrics.make_scorer(precision_0),\n",
    "                            'recall_0' : metrics.make_scorer(recall_0),\n",
    "                            'spec': metrics.make_scorer(specificity)\n",
    "                           } \n",
    "                \n",
    "                cv_scores = cross_validate(grid_pipeline.best_estimator_, X_train, y_train, \n",
    "                                           cv=cv_outer, scoring=scorings, n_jobs=-1, \n",
    "                                           return_train_score = False)\n",
    "\n",
    "                cv_f1_w_mean = np.mean(cv_scores[\"test_f1_weighted\"])\n",
    "                cv_f1_w_std = np.std(cv_scores[\"test_f1_weighted\"])\n",
    "                cv_p1_mean = np.mean(cv_scores[\"test_precision_1\"])\n",
    "                cv_p1_std = np.std(cv_scores[\"test_precision_1\"])\n",
    "                cv_r1_mean = np.mean(cv_scores[\"test_recall_1\"])\n",
    "                cv_r1_std = np.std(cv_scores[\"test_recall_1\"])                \n",
    "                cv_p0_mean = np.mean(cv_scores[\"test_precision_0\"])\n",
    "                cv_p0_std = np.std(cv_scores[\"test_precision_0\"])\n",
    "                cv_r0_mean = np.mean(cv_scores[\"test_recall_0\"])\n",
    "                cv_r0_std = np.std(cv_scores[\"test_recall_0\"])\n",
    "                \n",
    "                cv_auc_mean = np.mean(cv_scores[\"test_roc_auc\"])\n",
    "                cv_auc_std = np.std(cv_scores[\"test_roc_auc\"])                \n",
    "                cv_spec_mean = np.mean(cv_scores[\"test_spec\"])\n",
    "                cv_spec_std = np.std(cv_scores[\"test_spec\"])\n",
    "                cv_sens_mean = cv_r1_mean\n",
    "                cv_sens_std = cv_r1_std\n",
    "                \n",
    "                print \"\\nCV OUTER f1-weighted score: %0.3f  (+/-%0.03f)\" % (cv_f1_w_mean,cv_f1_w_std)               \n",
    "                print \"CV OUTER prec score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_p0_mean,cv_p0_std,cv_p1_mean,cv_p1_std)                \n",
    "                print \"CV OUTER rec  score [c=0,1]: {:.3f} (+/- {:.3f}), {:.3f}  (+/- {:.3f})\".format(cv_r0_mean,cv_r0_std,cv_r1_mean,cv_r1_std)\n",
    "                print \"CV OUTER AUC score: %0.3f  (+/-%0.03f)\" % (cv_auc_mean,cv_auc_std) \n",
    "                print \"CV OUTER Sensibility score: %0.3f  (+/-%0.03f)\" % (cv_sens_mean,cv_sens_std) \n",
    "                print \"CV OUTER Specificity score: %0.3f  (+/-%0.03f)\" % (cv_spec_mean,cv_spec_std)\n",
    "                print \"Selected params (bests from CV) {}\".format(grid_pipeline.best_params_.values())\n",
    "               \n",
    "\n",
    "                #Compute test scores\n",
    "                y_pred = grid_pipeline.best_estimator_.predict(X_test)\n",
    "                test_f1_w = metrics.f1_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "                test_p, test_r, test_f1, test_s = metrics.precision_recall_fscore_support(y_test, y_pred,labels=None,average=None, sample_weight=None)\n",
    "                fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "                test_auc = metrics.auc(fpr, tpr)                \n",
    "                cm_test = metrics.confusion_matrix(y_test, y_pred)\n",
    "                tn = cm_test[0,0]\n",
    "                fp = cm_test[0,1]\n",
    "                fn = cm_test[1,0]\n",
    "                tp = cm_test[1,1]\n",
    "                test_sens = test_r[1]\n",
    "                test_spec = tn / float(tn+fp)\n",
    "                \n",
    "                print \"\\nTEST f1 (weighted): %0.3f\" % (test_f1_w)\n",
    "                print \"TEST Precision [c=0,1]:\", test_p\n",
    "                print \"TEST Recall [c=0,1]:\", test_r                \n",
    "                print \"TEST AUC: %0.3f\" % (test_auc)                \n",
    "                print \"TEST Sensibility:\", test_sens\n",
    "                print \"TEST Specificity:\", test_spec\n",
    "                print \"Confussion matrix:\"\n",
    "                print \"         | PRED\"\n",
    "                print \"REAL-->  v \"\n",
    "                print cm_test\n",
    "\n",
    "                end = time.time()\n",
    "                print \"\\nTotal time:\", end - start\n",
    "                \n",
    "                res = [num_exp,\n",
    "                       name,\n",
    "                       tr_thr,\n",
    "                       fs,\n",
    "                       sm,\n",
    "                       cls,\n",
    "                       lm,\n",
    "                       grid_pipeline.best_params_.values(),\n",
    "                       train_sens,\n",
    "                       train_spec,\n",
    "                       train_auc,\n",
    "                       train_r,\n",
    "                       train_p,\n",
    "                       train_f1_w,\n",
    "                       cv_sens_mean,\n",
    "                       cv_sens_std,\n",
    "                       cv_spec_mean,\n",
    "                       cv_spec_std,\n",
    "                       cv_auc_mean,\n",
    "                       cv_auc_std,\n",
    "                       [cv_p0_mean,cv_p1_mean],\n",
    "                       [cv_p0_std,cv_p1_std],\n",
    "                       [cv_r0_mean,cv_r1_mean],\n",
    "                       [cv_r1_std,cv_r0_std],\n",
    "                       cv_f1_w_mean,\n",
    "                       cv_f1_w_std,\n",
    "                       test_sens,\n",
    "                       test_spec,\n",
    "                       test_auc,\n",
    "                       test_r,\n",
    "                       test_p,\n",
    "                       test_f1_w,\n",
    "                       cm_test,              \n",
    "                       end - start,\n",
    "                       grid_pipeline.best_estimator_\n",
    "                      ]\n",
    "                results.append(res)\n",
    "\n",
    "                #Save results\n",
    "                if save:\n",
    "                    df = pd.DataFrame(np.array(res).reshape(1,35), columns=\n",
    "                          [\"exp\", \"name\",\n",
    "                           \"size_tr\",\"fs\",\"sm\",\"cls\",\"metric\",\"params\",\n",
    "                           \"tr_sens\",\"tr_spec\",\"tr_auc\",\n",
    "                           \"tr_prec\",\"tr_rec\",\"tr_f1\",\n",
    "                           \"cv_sens_mean\",\"cv_sens_std\",\"cv_spec_mean\",\"cv_spec_std\",\"cv_auc_mean\",\"cv_auc_std\",\n",
    "                           \"cv_prec_mean\",\"cv_prec_std\",\"cv_rec_mean\",\"cv_rec_std\",\n",
    "                           \"cv_f1_mean\",\"cv_f1_std\",\n",
    "                           \"test_sens\",\"test_spec\",\"test_auc\",\n",
    "                           \"test_rec\",\"test_prec\",\"test_f1\",\n",
    "                           \"cm_test\",\n",
    "                           \"time\",\"pipeline\"])\n",
    "\n",
    "                    df.to_pickle(os.path.join(\"resources\", \"results\",\n",
    "                                          'results_pipe_' + \n",
    "                                          \"test_\" + str(ts_thr) + \"_\" +\n",
    "                                          \"train_\" + str(tr_thr) + \"_\" +\n",
    "                                          str(name) + '_' +\n",
    "                                          str(fs) + '_' +\n",
    "                                          str(sm) + '_' +\n",
    "                                          str(lm) + '_' +\n",
    "                                          str(cls) + '_' +\n",
    "                                          time.strftime(\"%Y%m%d-%H%M%S\") +\n",
    "                                          '.pkl'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeEncounter = \"last\" # ['first','last']\n",
    "typeHypothesis = \"early_readmission_vs_none\" # ['all_readmisssion_vs_none','early_readmission_vs_none']\n",
    "typeDataFeatures = \"extended_extra\" # [\"non_extended\",\"extended','extended_extra']\n",
    "    #Extended -> Subset of columns\n",
    "    #Minimum -> minimum set of columns \n",
    "typeDiagnosis = \"none\"  #[\"none\",\"diag_1\", \"diag_3\"]    \n",
    "typeDisease = \"subset\" # [\"subset\",\"any\",[\"Respiratory\",...]]\n",
    "    #subset -> Return subset of predefined disease features\n",
    "    #any -> Return all disease features    \n",
    "    #disease -> Return diseases feature\n",
    "typeDataExperiment = \"disease\" #[\"all\", \"disease\"] \n",
    "    #all -> Include all diagnosis as columns\n",
    "    #disease -> Remove diagnosis as column and keep only rows with diagnosis == 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "tr_thrs = [0.01] # [0.1,0.2,0.4,0.6,1.0]\n",
    "ts_thr = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs_methods = [\"none\",] #[\"none\",\"combine_fs\",\"lasso_fs\",\"rfe_rf_fs\"]\n",
    "cls_methods = [\"logReg\"] #[\"rf\",\"svmRBF\",\"logReg\",\"knn\",\"nn\",\"gbt\"]\n",
    "lms = [\"recall\"] #[\"f1_weighted\",\"precision_weighted\",\"roc_auc\",\"recall\"]\n",
    "sm_types = [\"after\"] #[\"none\",\"after\"]\n",
    "sm_method = \"sm_smote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fs' 'combine_fs' {'combine_fs__percentile': [5, 10, 20, 30, 40, 50]}]\n",
      " ['fs' 'rfe_rf_fs'\n",
      "  {'rfe_rf_fs__n_features_to_select': [5, 10, 15, 20], 'rfe_rf_fs__step': [0.1]}]\n",
      " ['fs' 'lasso_fs' {'lasso_fs__estimator__C': [0.001, 0.01, 0.1, 1]}]\n",
      " ['cls' 'knn'\n",
      "  {'knn__weights': ['uniform', 'distance'], 'knn__n_neighbors': [1, 3, 5, 7, 9, 11]}]\n",
      " ['cls' 'logReg'\n",
      "  {'logReg__class_weight': [None, 'balanced'], 'logReg__C': [1e-05, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 15, 30], 'logReg__penalty': ['l1', 'l2']}]\n",
      " ['cls' 'svmRBF'\n",
      "  {'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, 1, 5], 'svmRBF__class_weight': [None, 'balanced'], 'svmRBF__C': [0.01, 0.1, 0.5, 1, 5, 10, 30, 50, 100]}]\n",
      " ['cls' 'rf'\n",
      "  {'rf__criterion': ['entropy', 'gini'], 'rf__max_depth': [None, 4, 8, 12], 'rf__n_estimators': [200, 250, 300, 350, 400, 500]}]\n",
      " ['cls' 'nn'\n",
      "  {'nn__hidden_layer_sizes': [(30,), (50,), (70,), (100,), (150,), (30, 30), (50, 50), (70, 70), (100, 100), (30, 30, 30), (50, 50, 50), (70, 70, 70)], 'nn__alpha': [1e-05, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 3, 5, 10]}]\n",
      " ['cls' 'gbt'\n",
      "  {'gbt__max_depth': [None, 8, 10, 12], 'gbt__learning_rate': [0.1, 0.01, 0.001], 'gbt__n_estimators': [300, 400, 500]}]\n",
      " ['after' 'sm_smote' {'sm_smote__k_neighbors': [3, 4, 5]}]]\n"
     ]
    }
   ],
   "source": [
    "#Load default params\n",
    "hyperparams = np.load(\"../src/default_hyperparams.npy\")\n",
    "print hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(67182, 61)\n",
      "\n",
      "Initial columns:\n",
      "Index([u'gender', u'age', u'race_AfricanAmerican', u'race_Caucasian',\n",
      "       u'race_Other', u'HbA1c', u'Change', u'time_in_hospital', u'diabetesMed',\n",
      "       u'diss_home', u'medSpec_cardio', u'medSpec_Family/GeneralPractice',\n",
      "       u'medSpec_InternalMedicine', u'medSpec_surgery', u'adm_src_1',\n",
      "       u'adm_src_2', u'adm_src_3', u'adm_src_4', u'adm_src_5', u'adm_src_6',\n",
      "       u'adm_src_7', u'adm_src_8', u'adm_src_10', u'adm_src_11', u'adm_src_13',\n",
      "       u'adm_src_14', u'adm_src_22', u'adm_src_25', u'adm_1', u'adm_2',\n",
      "       u'adm_3', u'adm_4', u'adm_7', u'number_treatment',\n",
      "       u'num_lab_procedures', u'num_procedures', u'num_medications',\n",
      "       u'number_outpatient', u'number_emergency', u'number_inpatient',\n",
      "       u'number_diagnoses', u'insulin', u'metformin', u'pioglitazone',\n",
      "       u'glimepiride', u'glipizide', u'repaglinide', u'nateglinide',\n",
      "       u'ComplexHbA1c', u'add_in_out', u'add_procs_meds', u'div_visits_time',\n",
      "       u'div_em_time', u'div_visit_med', u'div_em_med', u'sum_ch_med',\n",
      "       u'number_treatment_0', u'number_treatment_1', u'number_treatment_2',\n",
      "       u'number_treatment_3', u'readmitted'],\n",
      "      dtype='object')\n",
      "\n",
      "Rows by class type:\n",
      "[0 1] 39785 5994\n",
      "\n",
      "Diseases: []\n",
      "\n",
      "Non-diseases: ['gender', 'age', 'race_AfricanAmerican', 'race_Caucasian', 'race_Other', 'HbA1c', 'Change', 'time_in_hospital', 'diabetesMed', 'diss_home', 'medSpec_cardio', 'medSpec_Family/GeneralPractice', 'medSpec_InternalMedicine', 'medSpec_surgery', 'adm_src_1', 'adm_src_2', 'adm_src_3', 'adm_src_4', 'adm_src_5', 'adm_src_6', 'adm_src_7', 'adm_src_8', 'adm_src_10', 'adm_src_11', 'adm_src_13', 'adm_src_14', 'adm_src_22', 'adm_src_25', 'adm_1', 'adm_2', 'adm_3', 'adm_4', 'adm_7', 'number_treatment', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'insulin', 'metformin', 'pioglitazone', 'glimepiride', 'glipizide', 'repaglinide', 'nateglinide', 'ComplexHbA1c', 'add_in_out', 'add_procs_meds', 'div_visits_time', 'div_em_time', 'div_visit_med', 'div_em_med', 'sum_ch_med', 'number_treatment_0', 'number_treatment_1', 'number_treatment_2', 'number_treatment_3', 'readmitted']\n",
      "\n",
      "Total data: (45779, 61)\n",
      "['subset']\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df_all = load_data(typeEncounter, typeDiagnosis, typeDataFeatures)\n",
    "print \"\\nSHAPE:\"\n",
    "print df_all.shape\n",
    "print \"\\nInitial columns:\"\n",
    "print df_all.columns\n",
    "\n",
    "#Filter data by class\n",
    "df_all = filter_data_by_class(df_all, typeHypothesis)\n",
    "print \"\\nRows by class type:\"\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)\n",
    "    \n",
    "#Get columns\n",
    "colsDiseases, colsNonDiseases = MLpipeline.get_columns(df_all,typeDiagnosis)\n",
    "print \"\\nDiseases:\", colsDiseases\n",
    "print \"\\nNon-diseases:\", colsNonDiseases\n",
    "    \n",
    "#Load diseases\n",
    "diseases = get_diseases(colsDiseases, typeDisease)\n",
    "print \"\\nTotal data:\", df_all.shape\n",
    "print diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataSet:\n",
      "**********\n",
      "**********\n",
      "SIZE: 0.01\n",
      "NAME: subset_extended_extra_disease_last_early_readmission_vs_none_none\n",
      "(45779, 61)\n",
      "ALL TRAIN: (320, 60)\n",
      "TRAIN: [0's: 278 1's: 42 ]\n",
      "ALL TEST: (13734, 60)\n",
      "TEST: [0's: 11936 1's: 1798 ]\n",
      "\n",
      "Num experiment: 0 / 0\n",
      "****************\n",
      "FS: none\n",
      "SM: after\n",
      "CLS: logReg\n",
      "METRIC: recall\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train f1 (weighted): 0.686\n",
      "Train Precision [c=0,1]: [ 0.92934783  0.21323529]\n",
      "Train Recall [c=0,1]: [ 0.61510791  0.69047619]\n",
      "Train AUC: 0.653\n",
      "Train Sensibility: 0.690476190476\n",
      "Train Specificity:  0.615107913669\n",
      "\n",
      "CV INNER metric: recall\n",
      "CV INNER selected params [None, 0.05, 'l1']\n",
      "CV INNER score: 0.646153846154\n",
      "\n",
      "CV OUTER f1-weighted score: 0.593  (+/-0.033)\n",
      "CV OUTER prec score [c=0,1]: 0.887 (+/- 0.012), 0.158  (+/- 0.016)\n",
      "CV OUTER rec  score [c=0,1]: 0.511 (+/- 0.041), 0.585  (+/- 0.038)\n",
      "CV OUTER AUC score: 0.581  (+/-0.049)\n",
      "CV OUTER Sensibility score: 0.585  (+/-0.038)\n",
      "CV OUTER Specificity score: 0.511  (+/-0.041)\n",
      "Selected params (bests from CV) [None, 0.05, 'l1']\n",
      "\n",
      "Test f1 (weighted): 0.651\n",
      "Test Precision [c=0,1]: [ 0.89353083  0.16401028]\n",
      "Test Recall [c=0,1]: [ 0.59132038  0.53225806]\n",
      "Test AUC: 0.562\n",
      "Test Sensibility: 0.532258064516\n",
      "Test Specificity: 0.591320375335\n",
      "Confussion matrix:\n",
      "         | PRED\n",
      "REAL-->  v \n",
      "[[7058 4878]\n",
      " [ 841  957]]\n",
      "\n",
      "Total time: 8.54507684708\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "for disease in diseases:\n",
    "    \n",
    "    df_all_filtered = filter_data_by_diseases(df_all, disease, typeDataExperiment, colsNonDiseases)\n",
    "    catCols, reducedCols = compute_type_features(df_all_filtered, typeDataFeatures)\n",
    "    \n",
    "    #Apply hyperparams changes\n",
    "    hyperparams = np.load(\"../src/default_hyperparams.npy\")\n",
    "    hyperparams[hyperparams[:,1] == 'rfe_rf_fs',2] =  [{'rfe_rf_fs__n_features_to_select': [int(len(reducedCols) * 0.2),\n",
    "                                                                                         int(len(reducedCols) * 0.4),\n",
    "                                                                                         int(len(reducedCols) * 0.6)], \n",
    "                                                                                         'rfe_rf_fs__step': [0.1]}]    \n",
    "\n",
    "    p = create_pipelines(catCols,reducedCols, hyperparams, fs_methods, sm_method, sm_types, cls_methods, lms)    \n",
    "\n",
    "    name = disease + \"_\" + typeDataFeatures + \"_\" +  typeDataExperiment + \"_\" + typeEncounter + \"_\" + \\\n",
    "           typeHypothesis + \"_\" + typeDiagnosis\n",
    "        \n",
    "    res = run(name, df_all_filtered, catCols, reducedCols, hyperparams, ts_thr, tr_thrs, \n",
    "                   fs_methods, sm_method, sm_types, \n",
    "                   cls_methods, lms, cv_folds, cv_thr, True, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  'subset_extended_extra_disease_last_early_readmission_vs_none_none',\n",
       "  0.01,\n",
       "  'none',\n",
       "  'after',\n",
       "  'logReg',\n",
       "  'recall',\n",
       "  [None, 0.05, 'l1'],\n",
       "  0.69047619047619047,\n",
       "  0,\n",
       "  0.65279205207262758,\n",
       "  array([ 0.61510791,  0.69047619]),\n",
       "  array([ 0.92934783,  0.21323529]),\n",
       "  0.68586750328323354,\n",
       "  0.58461538461538454,\n",
       "  0.037684457581279689,\n",
       "  0.51084337349397591,\n",
       "  0.041456989238759651,\n",
       "  0.58109360518999087,\n",
       "  0.049441996916956957,\n",
       "  [0.88651270925178971, 0.15848582540404987],\n",
       "  [0.012284391197954908, 0.015626190050576267],\n",
       "  [0.51084337349397591, 0.58461538461538454],\n",
       "  [0.037684457581279689, 0.041456989238759651],\n",
       "  0.5934727755533229,\n",
       "  0.033073194838440151,\n",
       "  0.532258064516129,\n",
       "  0.59132037533512061,\n",
       "  0.56178921992562481,\n",
       "  array([ 0.59132038,  0.53225806]),\n",
       "  array([ 0.89353083,  0.16401028]),\n",
       "  0.65132976138611676,\n",
       "  array([[7058, 4878],\n",
       "         [ 841,  957]]),\n",
       "  8.549112796783447,\n",
       "  Pipeline(memory=None,\n",
       "       steps=[('Imputer', TypeFeatImputer(allNameCols=Index([u'gender', u'age', u'race_AfricanAmerican', u'race_Caucasian',\n",
       "         u'race_Other', u'HbA1c', u'Change', u'time_in_hospital', u'diabetesMed',\n",
       "         u'diss_home', u'medSpec_cardio', u'medSpec_Family/GeneralPractice',\n",
       "         u'medSpec_InternalMed...alty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False))])]]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
