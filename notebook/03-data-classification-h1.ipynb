{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO RE-RUN\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from operator import truediv\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"/home/ilmira/healthforecast/readmission/src/\")\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71518, 20)\n",
      "Index([u'diss_1', u'race_AfricanAmerican', u'race_Caucasian', u'race_Other',\n",
      "       u'medSpec_cardio', u'medSpec_Family/GeneralPractice',\n",
      "       u'medSpec_InternalMedicine', u'medSpec_surgery', u'age_cat',\n",
      "       u'Diabetis', u'Circulatory', u'Digestive', u'Genitourinary',\n",
      "       u'Poisoning', u'Muscoskeletal', u'Neoplasms', u'Respiratory', u'HbA1c',\n",
      "       u'Change', u'readmitted'],\n",
      "      dtype='object')\n",
      "0    42985\n",
      "2    22240\n",
      "1     6293\n",
      "Name: readmitted, dtype: int64\n",
      "0   0.60\n",
      "2   0.31\n",
      "1   0.09\n",
      "Name: readmitted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#df_all=pd.read_csv(os.path.join('resources','diabetic_data_processed_withweight.csv'),';')\n",
    "df_all=pd.read_pickle(os.path.join('resources','clean_data_hyp_1.pkl'))\n",
    "print df_all.shape\n",
    "print df_all.columns\n",
    "print df_all.readmitted.value_counts()\n",
    "print df_all.readmitted.value_counts()/float(df_all.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] 42985 6293 22240\n"
     ]
    }
   ],
   "source": [
    "print df_all.loc[:,\"readmitted\"].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1), np.sum(df_all[\"readmitted\"] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] 42985 6293 22240\n",
      "[0 1] 42985 28533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Readmitted none vs readmitted\n",
    "df_all[\"readmitted\"][df_all[\"readmitted\"].values > 0] = 1\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] 42985 6293\n"
     ]
    }
   ],
   "source": [
    "# Readmitted none vs early readmitted\n",
    "df_all= df_all[df_all[\"readmitted\"].isin([0,1])]\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute type fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat cols: 19 \n",
      "Index([u'diss_1', u'race_AfricanAmerican', u'race_Caucasian', u'race_Other',\n",
      "       u'medSpec_cardio', u'medSpec_Family/GeneralPractice',\n",
      "       u'medSpec_InternalMedicine', u'medSpec_surgery', u'age_cat',\n",
      "       u'Diabetis', u'Circulatory', u'Digestive', u'Genitourinary',\n",
      "       u'Poisoning', u'Muscoskeletal', u'Neoplasms', u'Respiratory', u'HbA1c',\n",
      "       u'Change'],\n",
      "      dtype='object')\n",
      "Num cols: 0 \n",
      "Index([], dtype='object')\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "numCols = []\n",
    "catCols = []\n",
    "cols = df_all.columns\n",
    "reducedCols = cols[:-1]\n",
    "\n",
    "for i in range(len(cols)-1):\n",
    "    if cols[i] not in numCols:\n",
    "        catCols.append(1)\n",
    "    else:\n",
    "        catCols.append(0)\n",
    "catCols = np.array(catCols)\n",
    "\n",
    "print \"Cat cols:\", np.sum(catCols==1), \"\\n\", reducedCols[catCols==1]\n",
    "print \"Num cols:\", np.sum(catCols==0), \"\\n\", reducedCols[catCols==0]\n",
    "print len(reducedCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute partition (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "0    42985\n",
      "1     6293\n",
      "Name: readmitted, dtype: int64\n",
      "\n",
      "(34494, 19) (34494,)\n",
      "30089 0.87 4405 0.13\n",
      "(14784, 19) (14784,)\n",
      "12896 0.87 1888 0.13\n"
     ]
    }
   ],
   "source": [
    "y = df_all.readmitted\n",
    "print y.unique()\n",
    "print y.value_counts()\n",
    "y = y.values\n",
    "\n",
    "X = df_all.iloc[:,:-1].values\n",
    "sss = StratifiedShuffleSplit(y, 1, test_size=0.30, random_state=32) #random_state=42\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print\n",
    "print X_train.shape, y_train.shape\n",
    "print np.sum(y_train == 0), round(np.sum(y_train == 0)/float(y_train.shape[0]),2), \\\n",
    "      np.sum(y_train > 0), round(np.sum(y_train > 0)/float(y_train.shape[0]),2)\n",
    "print X_test.shape, y_test.shape\n",
    "print np.sum(y_test == 0), round(np.sum(y_test == 0)/float(y_test.shape[0]),2), \\\n",
    "      np.sum(y_test > 0), round(np.sum(y_test > 0)/float(y_test.shape[0]),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basePipeline = Pipeline([\n",
    "        (\"Imputer\", TypeFeatImputer(catCols, reducedCols)),\n",
    "        (\"Variance\", VarianceThreshold(threshold=(.995 * (1 - .995)))),\n",
    "        (\"Scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "params = {}\n",
    "pipeline = []\n",
    "pipe = Pipeline(list(basePipeline.steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs_method = \"combine_fs\"\n",
    "pipe.steps.insert(1,(fs_method, UnivCombineFilter(catCols,np.array(reducedCols))))\n",
    "params.update({fs_method + '__percentile':[30,50,70,80]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_method = \"logReg\"\n",
    "pipe.steps.append((cls_method, LogisticRegression(random_state=42)))\n",
    "params.update({cls_method + '__C': [1e-8,1e-6,1e-5,0.001,0.01,0.1,1,5,10]})\n",
    "params.update({cls_method + '__class_weight': [None, 'balanced']})\n",
    "params.update({cls_method + '__penalty': [\"l1\",\"l2\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_method = \"rf\"\n",
    "pipe.steps.append((cls_method, RandomForestClassifier(n_jobs=-1,random_state=42,class_weight=\"balanced\")))\n",
    "params.update({cls_method + '__n_estimators': [150,300,500,700], \n",
    "               cls_method + '__criterion': ['gini'],\n",
    "               cls_method + '__max_depth' : [None,4,6,8,10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_method = \"knn\"\n",
    "pipe.steps.append((cls_method, KNeighborsClassifier(n_jobs=-1)))\n",
    "\n",
    "params.update({cls_method + '__n_neighbors': [3,5,7,9], \n",
    "               cls_method + '__weights': ['uniform', 'distance']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_method = \"svm\"\n",
    "pipe.steps.append((cls_method, SVC(kernel = \"rbf\", random_state=42,probability=True)))\n",
    "params.update({cls_method + '__C': [0.01,0.1,0.5,1,5,10,15,30,50], \n",
    "               cls_method + '__gamma' : [0.0001,0.001,0.01, 0.1,1,5],\n",
    "               cls_method + '__class_weight': [None, 'balanced']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls_method = \"nb\"\n",
    "pipe.steps.append((cls_method, GaussianNB()))\n",
    "#params.update({cls_method + '__alpha': [1e-3,0.001,0.01,0.1,0.5,1,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Post process pipeline\n",
    "pipe_imb = make_pipeline(*[p[1] for p in pipe.steps])\n",
    "stps = len(pipe_imb.steps)        \n",
    "for s in range(stps):\n",
    "    pipe_imb.steps.remove(pipe_imb.steps[0])\n",
    "for s in range(stps):\n",
    "    pipe_imb.steps.append(pipe.steps[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add sampling\n",
    "sm_method = \"smote\"                \n",
    "pipe_imb.steps.insert(stps - 1, \n",
    "                      (sm_method, SMOTE(ratio='auto', kind='regular', random_state=32)))\n",
    "params.update({sm_method + \"__k_neighbors\":[3,4,5]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Imputer', TypeFeatImputer(allNameCols=Index([u'diss_1', u'race_AfricanAmerican', u'race_Caucasian', u'race_Other',\n",
      "       u'medSpec_cardio', u'medSpec_Family/GeneralPractice',\n",
      "       u'medSpec_InternalMedicine', u'medSpec_surgery', u'age_cat',\n",
      "       u'Diabetis', u'Circulatory', u'Digestive', u'Genitourinary',\n",
      "       u'Poisoning', u'Muscoskeletal', u'Neoplasms', u'Respiratory', u'HbA1c',\n",
      "       u'Change'],\n",
      "      dtype='object'),\n",
      "        dataCatCols=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))), ('Variance', VarianceThreshold(threshold=0.004975)), ('Scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logReg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "mtrs = [\"f1_weighted\",\"recall\"] #\"f1\",\"recall\",\"precision\"\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "print pipe_imb.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL TRAIN: (34494, 19)\n",
      "TRAIN: [0's: 30089 1's: 4405 ]\n",
      "ALL TEST: (14784, 19)\n",
      "TEST: [0's: 12896 1's: 1888 ]\n",
      "TEST: [0's: 0.872294372294 1's: 0.127705627706 ]\n",
      "\n",
      "CV TRAIN: 24145\n",
      "CV_TEST: 10349\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    4.3s\n"
     ]
    }
   ],
   "source": [
    "print \"ALL TRAIN:\", X_train.shape\n",
    "print \"TRAIN:\", \"[0's:\", np.sum(y_train==0), \"1's:\", np.sum(y_train==1), \"]\"\n",
    "print \"ALL TEST:\", X_test.shape\n",
    "print \"TEST:\", \"[0's:\", np.sum(y_test==0), \"1's:\", np.sum(y_test==1), \"]\"\n",
    "print \"TEST:\", \"[0's:\", np.sum(y_test==0)/float(y_test.shape[0]), \"1's:\", np.sum(y_test==1)/float(y_test.shape[0]), \"]\"\n",
    "\n",
    "# Run experiment\n",
    "start = time.time()\n",
    "\n",
    "#Prepare pipe_cls      \n",
    "pipeline_cls = pipe_imb\n",
    "pipeline_params = params\n",
    "\n",
    "if verbose:\n",
    "    print \"\\n\",pipeline_cls.steps\n",
    "\n",
    "\n",
    "#Prepare cv\n",
    "cv_inner = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr,random_state=24)\n",
    "\n",
    "print \"\\nCV TRAIN:\", cv_inner.n_train\n",
    "print \"CV_TEST:\", cv_inner.n_test\n",
    "\n",
    "#Fit pipeline with CV                        \n",
    "grid_pipelines = []\n",
    "\n",
    "for m in mtrs:\n",
    "    grid_pipeline = GridSearchCV(pipeline_cls, param_grid=pipeline_params, verbose=1, \n",
    "                                 n_jobs=-1, cv=cv_inner, scoring= m, error_score = 0,\n",
    "                                 refit=True) \n",
    "    grid_pipeline.fit(X_train, y_train)\n",
    "    grid_pipelines.append([m,grid_pipeline])\n",
    "\n",
    "end = time.time()\n",
    "print \"Total time:\", end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1_weighted\n",
      "*****\n",
      "\n",
      "('logReg', LogisticRegression(C=1e-05, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))\n",
      "\n",
      "Discarded feats: 0 Index([], dtype='object')\n",
      "\n",
      "recall\n",
      "*****\n",
      "\n",
      "('logReg', LogisticRegression(C=1e-05, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))\n",
      "\n",
      "Discarded feats: 0 Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for gp in grid_pipelines:\n",
    "    print\n",
    "    print gp[0]\n",
    "    print \"*****\\n\"\n",
    "    print gp[1].best_estimator_.steps[-1]\n",
    "    print\n",
    "    \n",
    "    if gp[1].best_estimator_.steps[1][0] == \"combine_fs\":\n",
    "        varFilter = gp[1].best_estimator_.steps[1][1]\n",
    "\n",
    "        print \"Selected thr:\", varFilter.percentile\n",
    "        print \"Selected columns:\"\n",
    "        feats = reducedCols[varFilter.ixCols].tolist()\n",
    "        print feats\n",
    "        print \"Num useful features:\", len(feats), feats\n",
    "    \n",
    "    if gp[1].best_estimator_.steps[1][0] == \"Variance\":\n",
    "        varFilter = gp[1].best_estimator_.steps[1][1]\n",
    "        feats = reducedCols[varFilter.get_support() == False]\n",
    "        print \"Discarded feats:\", len(feats), feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN: \n",
      "**********\n",
      "\n",
      "Metric: f1_weighted\n",
      "TR Prec score: 0.760901412974\n",
      "TR Rec score: 0.872296631298\n",
      "TR F1 score: 0.812800066244\n",
      "\n",
      "TRAIN: \n",
      "**********\n",
      "\n",
      "Metric: recall\n",
      "TR Prec score: 0.80972382947\n",
      "TR Rec score: 0.560851162521\n",
      "TR F1 score: 0.633207840783\n"
     ]
    }
   ],
   "source": [
    "# Computel Train score (with best CV params)\n",
    "for gp in grid_pipelines:\n",
    "    \n",
    "    cls = gp[1]\n",
    "    y_pred = cls.predict(X_train)                \n",
    "    train_prec_scores = metrics.precision_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "    train_rec_scores = metrics.recall_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "    train_f1_scores = metrics.f1_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "\n",
    "    print \"\\nTRAIN: \"\n",
    "    print \"**********\\n\"\n",
    "\n",
    "    print \"Metric:\",gp[0]\n",
    "    print \"TR Prec score:\", train_prec_scores\n",
    "    print \"TR Rec score:\", train_rec_scores\n",
    "    print \"TR F1 score:\", train_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV: \n",
      "******\n",
      "\n",
      "Metric: f1_weighted\n",
      "CV selected params [None, 1e-05, 'l1']\n",
      "CV f1_weighted score: 0.812745114975\n",
      "CV f1 score: 0.813  (+/-0.000)\n",
      "\n",
      "CV: \n",
      "******\n",
      "\n",
      "Metric: recall\n",
      "CV selected params ['balanced', 1e-05, 'l2']\n",
      "CV recall score: 0.604841149773\n",
      "CV f1 score: 0.631  (+/-0.004)\n"
     ]
    }
   ],
   "source": [
    "# Compute pipeline evaluation with CV\n",
    "for gp in grid_pipelines:\n",
    "    \n",
    "    cls = gp[1]\n",
    "    print \"\\nCV: \"\n",
    "    print \"******\\n\"\n",
    "    \n",
    "    print \"Metric:\", gp[0]\n",
    "    print \"CV selected params {}\".format(cls.best_params_.values())\n",
    "    cv_inner_f1 = cross_val_score(cls.best_estimator_, X_train, y_train, \n",
    "                                             cv=cv_inner, scoring='f1_weighted', n_jobs=-1)\n",
    "    print \"CV {} score: {}\".format(gp[0], cls.best_score_)\n",
    "    print \"CV f1 score: %0.3f  (+/-%0.03f)\" % (np.mean(cv_inner_f1), np.std(cv_inner_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_weighted\n",
      "                       params score_mean score_std  \\\n",
      "0         [None, 1e-05, 'l1']       0.81      0.00   \n",
      "1         [None, 1e-05, 'l2']       0.81      0.00   \n",
      "2   ['balanced', 1e-05, 'l1']       0.81      0.00   \n",
      "3   ['balanced', 1e-05, 'l2']       0.63      0.00   \n",
      "4         [None, 0.001, 'l1']       0.81      0.00   \n",
      "5         [None, 0.001, 'l2']       0.81      0.00   \n",
      "6   ['balanced', 0.001, 'l1']       0.68      0.00   \n",
      "7   ['balanced', 0.001, 'l2']       0.65      0.00   \n",
      "8          [None, 0.01, 'l1']       0.81      0.00   \n",
      "9          [None, 0.01, 'l2']       0.81      0.00   \n",
      "10   ['balanced', 0.01, 'l1']       0.65      0.00   \n",
      "11   ['balanced', 0.01, 'l2']       0.65      0.00   \n",
      "12          [None, 0.1, 'l1']       0.81      0.00   \n",
      "13          [None, 0.1, 'l2']       0.81      0.00   \n",
      "14    ['balanced', 0.1, 'l1']       0.65      0.00   \n",
      "15    ['balanced', 0.1, 'l2']       0.65      0.00   \n",
      "16            [None, 1, 'l1']       0.81      0.00   \n",
      "17            [None, 1, 'l2']       0.81      0.00   \n",
      "18      ['balanced', 1, 'l1']       0.65      0.00   \n",
      "19      ['balanced', 1, 'l2']       0.65      0.00   \n",
      "20            [None, 5, 'l1']       0.81      0.00   \n",
      "21            [None, 5, 'l2']       0.81      0.00   \n",
      "22      ['balanced', 5, 'l1']       0.65      0.00   \n",
      "23      ['balanced', 5, 'l2']       0.65      0.00   \n",
      "24           [None, 10, 'l1']       0.81      0.00   \n",
      "25           [None, 10, 'l2']       0.81      0.00   \n",
      "26     ['balanced', 10, 'l1']       0.65      0.00   \n",
      "27     ['balanced', 10, 'l2']       0.65      0.00   \n",
      "\n",
      "                                               scores  \n",
      "0   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "1   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "2   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "3   [0.6259441447, 0.631858211843, 0.632164639002,...  \n",
      "4   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "5   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "6   [0.678144498405, 0.680954248725, 0.68249920214...  \n",
      "7   [0.647472594414, 0.648190940731, 0.65326732467...  \n",
      "8   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "9   [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "10  [0.643891700907, 0.649559680529, 0.65033464663...  \n",
      "11  [0.650833056556, 0.652133887181, 0.65400305576...  \n",
      "12  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "13  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "14  [0.650422878515, 0.653686568758, 0.65498353487...  \n",
      "15  [0.651487401143, 0.651800054784, 0.65432976725...  \n",
      "16  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "17  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "18  [0.651403997983, 0.652622690371, 0.65432976725...  \n",
      "19  [0.651487401143, 0.652458014746, 0.65432976725...  \n",
      "20  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "21  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "22  [0.651487401143, 0.652458014746, 0.65432976725...  \n",
      "23  [0.651487401143, 0.652458014746, 0.65432976725...  \n",
      "24  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "25  [0.812745114975, 0.812745114975, 0.81274511497...  \n",
      "26  [0.651487401143, 0.652458014746, 0.65432976725...  \n",
      "27  [0.651487401143, 0.652458014746, 0.65432976725...  \n",
      "recall\n",
      "                       params score_mean score_std  \\\n",
      "0         [None, 1e-05, 'l1']       0.00      0.00   \n",
      "1         [None, 1e-05, 'l2']       0.00      0.00   \n",
      "2   ['balanced', 1e-05, 'l1']       0.00      0.00   \n",
      "3   ['balanced', 1e-05, 'l2']       0.60      0.01   \n",
      "4         [None, 0.001, 'l1']       0.00      0.00   \n",
      "5         [None, 0.001, 'l2']       0.00      0.00   \n",
      "6   ['balanced', 0.001, 'l1']       0.52      0.01   \n",
      "7   ['balanced', 0.001, 'l2']       0.58      0.01   \n",
      "8          [None, 0.01, 'l1']       0.00      0.00   \n",
      "9          [None, 0.01, 'l2']       0.00      0.00   \n",
      "10   ['balanced', 0.01, 'l1']       0.59      0.00   \n",
      "11   ['balanced', 0.01, 'l2']       0.57      0.00   \n",
      "12          [None, 0.1, 'l1']       0.00      0.00   \n",
      "13          [None, 0.1, 'l2']       0.00      0.00   \n",
      "14    ['balanced', 0.1, 'l1']       0.57      0.00   \n",
      "15    ['balanced', 0.1, 'l2']       0.57      0.01   \n",
      "16            [None, 1, 'l1']       0.00      0.00   \n",
      "17            [None, 1, 'l2']       0.00      0.00   \n",
      "18      ['balanced', 1, 'l1']       0.57      0.00   \n",
      "19      ['balanced', 1, 'l2']       0.57      0.01   \n",
      "20            [None, 5, 'l1']       0.00      0.00   \n",
      "21            [None, 5, 'l2']       0.00      0.00   \n",
      "22      ['balanced', 5, 'l1']       0.57      0.00   \n",
      "23      ['balanced', 5, 'l2']       0.57      0.01   \n",
      "24           [None, 10, 'l1']       0.00      0.00   \n",
      "25           [None, 10, 'l2']       0.00      0.00   \n",
      "26     ['balanced', 10, 'l1']       0.57      0.00   \n",
      "27     ['balanced', 10, 'l2']       0.57      0.01   \n",
      "\n",
      "                                               scores  \n",
      "0                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "1                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "2                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "3   [0.60363086233, 0.612708018154, 0.597579425113...  \n",
      "4                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "5                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "6   [0.516641452345, 0.527987897126, 0.50983358547...  \n",
      "7   [0.57791225416, 0.583207261725, 0.580181543116...  \n",
      "8                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "9                           [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "10  [0.587745839637, 0.590015128593, 0.57866868381...  \n",
      "11  [0.575642965204, 0.577155824508, 0.57866868381...  \n",
      "12                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "13                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "14  [0.576399394856, 0.5741301059, 0.575642965204,...  \n",
      "15  [0.574886535552, 0.580181543116, 0.57791225416...  \n",
      "16                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "17                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "18  [0.575642965204, 0.577155824508, 0.57791225416...  \n",
      "19  [0.574886535552, 0.57791225416, 0.57791225416,...  \n",
      "20                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "21                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "22  [0.574886535552, 0.57791225416, 0.57791225416,...  \n",
      "23  [0.574886535552, 0.57791225416, 0.57791225416,...  \n",
      "24                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "25                          [0.0, 0.0, 0.0, 0.0, 0.0]  \n",
      "26  [0.574886535552, 0.57791225416, 0.57791225416,...  \n",
      "27  [0.574886535552, 0.57791225416, 0.57791225416,...  \n"
     ]
    }
   ],
   "source": [
    "# Compute pipeline evaluation with CV\n",
    "dd = []\n",
    "for gp in grid_pipelines:\n",
    "    \n",
    "    cls = gp[1]   \n",
    "    params =  np.array([str(d.values()) for d in np.array(cls.grid_scores_[:])[:,0]])\n",
    "    mean = np.array(cls.grid_scores_)[:,1]\n",
    "    values = np.array(cls.grid_scores_)[:,2]\n",
    "    std = np.array([np.std(v) for v in values])\n",
    "    \n",
    "    dd = np.hstack((params.reshape(-1,1), mean.reshape(-1,1), std.reshape(-1,1), values.reshape(-1,1)))\n",
    "    \n",
    "\n",
    "    res = pd.DataFrame(dd,columns=[\"params\",\"score_mean\",\"score_std\",\"scores\"])\n",
    "    print gp[0]\n",
    "    print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1_weighted :\n",
      "**********\n",
      "\n",
      "Test f1: 0.813\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      1.00      0.93     12896\n",
      "          1       0.00      0.00      0.00      1888\n",
      "\n",
      "avg / total       0.76      0.87      0.81     14784\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12896     0]\n",
      " [ 1888     0]]\n",
      "\n",
      "Accuracy: 0.872294372294\n",
      "Sensitivity: 0.0\n",
      "Specificity: 1.0\n",
      "AUC: 0.5\n",
      "\n",
      "recall :\n",
      "**********\n",
      "\n",
      "Test f1: 0.630\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.55      0.68     12896\n",
      "          1       0.17      0.61      0.26      1888\n",
      "\n",
      "avg / total       0.81      0.56      0.63     14784\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[7096 5800]\n",
      " [ 740 1148]]\n",
      "\n",
      "Accuracy: 0.55762987013\n",
      "Sensitivity: 0.608050847458\n",
      "Specificity: 0.550248138958\n",
      "AUC: 0.607509604213\n"
     ]
    }
   ],
   "source": [
    "#Compute test score\n",
    "for gp in grid_pipelines:\n",
    "    \n",
    "    cls = gp[1]\n",
    "    y_pred =cls.predict(X_test)\n",
    "    test_f1 = metrics.f1_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "\n",
    "    print \"\\n\",gp[0],\":\"\n",
    "    print \"**********\\n\"\n",
    "    print \"Test f1: %0.3f\" % (test_f1)\n",
    "    print \"with following performance in test:\"\n",
    "    print metrics.classification_report(y_test, y_pred)\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print \"\\nConfusion matrix:\"\n",
    "    print cm\n",
    "\n",
    "    print \"\\nAccuracy:\", (cm[0,0] + cm[1,1])/ float(cm[0,0] + cm[1,1]+cm[0,1] + cm[1,0])\n",
    "    print \"Sensitivity:\", cm[1,1] / float(cm[1,1] + cm[1,0]) #Reduce FN (recall)\n",
    "    print \"Specificity:\", cm[0,0] / float(cm[0,0] + cm[0,1]) #Reduce FP\n",
    "\n",
    "    y_probs = cls.best_estimator_.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_probs[:,1], pos_label=1)\n",
    "    print \"AUC:\", metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedShuffleSplit(labels=[0 1 ..., 0 0], n_iter=10, test_size=0.2, random_state=24),\n",
      "       error_score=0,\n",
      "       estimator=Pipeline(steps=[('Imputer', TypeFeatImputer(allNameCols=Index([u'gender', u'age', u'time_in_hospital', u'num_lab_procedures',\n",
      "       u'num_procedures', u'num_medications', u'number_outpatient',\n",
      "       u'number_emergency', u'number_inpatient', u'number_diagnoses',\n",
      "       u'metformin', u'repaglinide', u'glimep...alty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'logReg__class_weight': [None, 'balanced'], 'logReg__C': [0.001, 1, 10], 'logReg__penalty': ['l1', 'l2']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring='recall', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "cls = grid_pipelines[1][1]\n",
    "print cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"% Training set\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    train_sizes_lc, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,scoring=\"f1_weighted\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.axhline(0.5,color='r',ls='--', label=\"random\")\n",
    "    \n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/aegle/miniconda2/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAF6CAYAAADLb5pWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f167d978290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "title = \"\"\n",
    "plot_learning_curve(cls.best_estimator_, title, X_train, y_train, ylim=(0.4, 1.01), \n",
    "                    cv=cv_inner,\n",
    "                    train_sizes=[0.05,0.10,0.15,0.25,0.50,0.75,0.80,1.0], \n",
    "                    n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
