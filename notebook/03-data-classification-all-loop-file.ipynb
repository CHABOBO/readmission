{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO RE-RUN\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from operator import truediv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../src/\")\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter\n",
    "import MLpipeline as MLpipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall_func(y_test, y_pred):\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    test_auc = metrics.auc(fpr, tpr)\n",
    "    tn = cm[0,0]\n",
    "    fp = cm[0,1]\n",
    "    fn = cm[1,0]\n",
    "    tp = cm[1,1]    \n",
    "    \n",
    "    return fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeEncounter = \"last\" # ['first','last']\n",
    "typeHypothesis = \"all_readmisssion_vs_none\" # ['all_readmisssion_vs_none','early_readmission_vs_none']\n",
    "typeDataFeatures = \"extended\" # [\"minimum,\"extended']\n",
    "    #Extended -> Subset of columns\n",
    "    #Minimum -> minimum set of columns \n",
    "typeDiagnosis = \"diag_1\"  #[\"diag_1\", \"diag_3\"]    \n",
    "typeDisease = \"Neoplasms_1\" # [\"subset\",\"any\",[\"Respiratory\",...]]\n",
    "    #subset -> Return subset of predefined disease features\n",
    "    #any -> Return all disease features    \n",
    "    #disase -> Return diases feature\n",
    "typeDataExperiment = \"disease\" #[\"all\", \"disease\"] \n",
    "    #all -> Include all diagnosis as columns\n",
    "    #disease -> Remove diagnosis as column and keep only rows with diagnosis == 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "tr_thrs = [1.0] # [0.2,0.4,0.6,1.0]\n",
    "ts_thr = 0.30\n",
    "\n",
    "fs_methods = [\"none\"] #[\"none\",\"combine_fs\",\"lasso_fs\",\"rfe_rf_fs\"]\n",
    "cls_methods = [\"rf\"] #[\"rf\",\"svmRBF\",\"logReg\",\"knn\",\"nn\"]\n",
    "lms = [\"recall_micro\",\"f1_weighted\"] #[\"f1_weighted\",\"precision_weighted\",\"roc_auc\",\"recall]\n",
    "sm_types = [\"none\"] #[\"none\",\"after\"]\n",
    "sm_method = \"sm_smote\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SHAPE:\n",
      "(71518, 30)\n",
      "\n",
      "Initial columns:\n",
      "Index([u'diss_1', u'adm_src_ref', u'adm_src_em', u'race_AfricanAmerican',\n",
      "       u'race_Caucasian', u'race_Other', u'medSpec_cardio',\n",
      "       u'medSpec_Family/GeneralPractice', u'medSpec_InternalMedicine',\n",
      "       u'medSpec_surgery', u'age_cat', u'Diabetis_1', u'Circulatory_1',\n",
      "       u'Digestive_1', u'Genitourinary_1', u'Poisoning_1', u'Muscoskeletal_1',\n",
      "       u'Neoplasms_1', u'Respiratory_1', u'HbA1c', u'Change',\n",
      "       u'time_in_hospital', u'num_lab_procedures', u'num_procedures',\n",
      "       u'num_medications', u'number_outpatient', u'number_emergency',\n",
      "       u'number_inpatient', u'number_diagnoses', u'readmitted'],\n",
      "      dtype='object')\n",
      "\n",
      "Rows by class type:\n",
      "[0 1] 42985 28533\n",
      "\n",
      "Diseases: [u'Diabetis_1', u'Circulatory_1', u'Digestive_1', u'Genitourinary_1', u'Poisoning_1', u'Muscoskeletal_1', u'Neoplasms_1', u'Respiratory_1']\n",
      "\n",
      "Non-diseases: ['diss_1', 'adm_src_ref', 'adm_src_em', 'race_AfricanAmerican', 'race_Caucasian', 'race_Other', 'medSpec_cardio', 'medSpec_Family/GeneralPractice', 'medSpec_InternalMedicine', 'medSpec_surgery', 'age_cat', 'HbA1c', 'Change', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'readmitted']\n",
      "\n",
      "Total data: (71518, 30)\n",
      "['Neoplasms_1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/MLpipeline.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_all[\"readmitted\"][df_all[\"readmitted\"].values > 0] = 1\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df_all = MLpipeline.load_data(typeEncounter, typeDiagnosis, typeDataFeatures)\n",
    "print \"\\nSHAPE:\"\n",
    "print df_all.shape\n",
    "print \"\\nInitial columns:\"\n",
    "print df_all.columns\n",
    "\n",
    "#Filter data by class\n",
    "df_all = MLpipeline.filter_data_by_class(df_all, typeHypothesis)\n",
    "print \"\\nRows by class type:\"\n",
    "print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1)\n",
    "    \n",
    "#Get columns\n",
    "colsDiseases, colsNonDiseases = MLpipeline.get_columns(df_all,typeDiagnosis)\n",
    "print \"\\nDiseases:\", colsDiseases\n",
    "print \"\\nNon-diseases:\", colsNonDiseases\n",
    "    \n",
    "#Load diseases\n",
    "diseases = MLpipeline.get_diseases(colsDiseases, typeDisease)\n",
    "print \"\\nTotal data:\", df_all.shape\n",
    "print diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6)\n",
      "\n",
      "DataSet:\n",
      "**********\n",
      "**********\n",
      "SIZE: 1.0\n",
      "DISEASE: Neoplasms_1\n",
      "(2718, 22)\n",
      "ALL TRAIN: (1902, 21)\n",
      "TRAIN: [0's: 1327 1's: 575 ]\n",
      "ALL TEST: (816, 21)\n",
      "TEST: [0's: 570 1's: 246 ]\n",
      "\n",
      "Num experiment: 0 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: recall_micro\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   52.6s finished\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV INNER metric: recall_micro\n",
      "CV INNER selected params ['gini', 6, None, 100]\n",
      "CV INNER score: 0.702276707531\n",
      "\n",
      "CV OUTER f1 score: 0.587  (+/-0.005)\n",
      "CV OUTER prec score: 0.661  (+/-0.056)\n",
      "CV OUTER rec score: 0.698  (+/-0.005)\n",
      "Selected params (bests from CV) ['gini', 6, None, 100]\n",
      "\n",
      "TR F1 score: 0.62868448227\n",
      "TR Prec score: 0.801682382821\n",
      "TR Rec score: 0.722923238696\n",
      "\n",
      "Test f1 (weighted): 0.583\n",
      "Test Precision (weighted): 0.697\n",
      "Test Recall / Sensitivity (weighted): 0.623\n",
      "Test AUC (weighted): 0.504\n",
      "Test Sensitivity: 0.016\n",
      "Test Specificity: 0.991\n",
      "Test AUC: 0.504\n",
      "\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.99      0.82       570\n",
      "          1       0.44      0.02      0.03       246\n",
      "\n",
      "avg / total       0.62      0.70      0.58       816\n",
      "\n",
      "[[565   5]\n",
      " [242   4]]\n",
      "\n",
      "Total time: 57.2521739006\n",
      "\n",
      "Num experiment: 1 / 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: f1_weighted\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.8s\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   52.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV INNER metric: f1_weighted\n",
      "CV INNER selected params ['gini', 6, 'balanced', 200]\n",
      "CV INNER score: 0.662973278309\n",
      "\n",
      "CV OUTER f1 score: 0.652  (+/-0.015)\n",
      "CV OUTER prec score: 0.653  (+/-0.014)\n",
      "CV OUTER rec score: 0.650  (+/-0.016)\n",
      "Selected params (bests from CV) ['gini', 6, 'balanced', 200]\n",
      "\n",
      "TR F1 score: 0.783485759437\n",
      "TR Prec score: 0.790159067349\n",
      "TR Rec score: 0.779705573081\n",
      "\n",
      "Test f1 (weighted): 0.613\n",
      "Test Precision (weighted): 0.605\n",
      "Test Recall / Sensitivity (weighted): 0.623\n",
      "Test AUC (weighted): 0.555\n",
      "Test Sensitivity: 0.427\n",
      "Test Specificity: 0.682\n",
      "Test AUC: 0.555\n",
      "\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.68      0.71       570\n",
      "          1       0.37      0.43      0.39       246\n",
      "\n",
      "avg / total       0.62      0.61      0.61       816\n",
      "\n",
      "[[389 181]\n",
      " [141 105]]\n",
      "\n",
      "Total time: 59.6393430233\n"
     ]
    }
   ],
   "source": [
    "res = MLpipeline.run(df_all, colsNonDiseases, diseases, typeDataFeatures, \n",
    "               typeDataExperiment, typeEncounter, typeHypothesis, typeDiagnosis, ts_thr, tr_thrs, \n",
    "               fs_methods, sm_method, sm_types, \n",
    "               cls_methods, lms, cv_folds, cv_thr, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not dfAux\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_tr</th>\n",
       "      <th>sm</th>\n",
       "      <th>metric</th>\n",
       "      <th>cls</th>\n",
       "      <th>params</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_prec</th>\n",
       "      <th>tr_rec</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>cv_prec_mean</th>\n",
       "      <th>cv_rec_mean</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>none</td>\n",
       "      <td>recall_micro</td>\n",
       "      <td>rf</td>\n",
       "      <td>[gini, 6, None, 100]</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>none</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>rf</td>\n",
       "      <td>[gini, 6, balanced, 200]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size_tr    sm        metric cls                    params tr_f1 tr_prec  \\\n",
       "0    1.00  none  recall_micro  rf      [gini, 6, None, 100]  0.63    0.80   \n",
       "1    1.00  none   f1_weighted  rf  [gini, 6, balanced, 200]  0.78    0.79   \n",
       "\n",
       "  tr_rec cv_f1_mean cv_prec_mean cv_rec_mean test_f1 test_prec test_rec  \\\n",
       "0   0.72       0.59         0.66        0.70    0.58      0.70     0.62   \n",
       "1   0.78       0.65         0.65        0.65    0.61      0.61     0.62   \n",
       "\n",
       "  test_auc  \n",
       "0     0.50  \n",
       "1     0.55  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'dfAux' not in locals():\n",
    "    print \"Not dfAux\"\n",
    "    dfAux = pd.DataFrame()\n",
    "\n",
    "if 'df' in locals():\n",
    "    print \"Exist df\"\n",
    "    dfAux = df.copy()\n",
    "    \n",
    "df = pd.DataFrame(np.array(res).reshape(len(res),27), columns=\n",
    "                          [\"exp\", \"typeDisease\",\"typeEncounter\",\"typeHypothesis\",\"typeDataFeatures\",\"typeDiagnosis\",\n",
    "                           \"size_tr\",\"fs\",\"sm\",\"cls\",\"metric\",\"params\",\n",
    "                           \"tr_f1\",\"tr_prec\",\"tr_rec\",\n",
    "                           \"cv_f1_mean\",\"cv_f1_std\",\"cv_prec_mean\",\"cv_prec_std\",\"cv_rec_mean\",\"cv_rec_std\",\n",
    "                           \"test_f1\",\"test_prec\",\"test_rec\",\"test_auc\",\n",
    "                           \"time\",\"pipeline\"])\n",
    "\n",
    "df[[\"size_tr\",\"sm\",\"metric\",\"cls\",\"params\", 'tr_f1', 'tr_prec', 'tr_rec', \n",
    "     'cv_f1_mean', 'cv_prec_mean', 'cv_rec_mean', 'test_f1', 'test_prec', 'test_rec', 'test_auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_tr</th>\n",
       "      <th>sm</th>\n",
       "      <th>metric</th>\n",
       "      <th>cls</th>\n",
       "      <th>params</th>\n",
       "      <th>tr_f1</th>\n",
       "      <th>tr_prec</th>\n",
       "      <th>tr_rec</th>\n",
       "      <th>cv_f1_mean</th>\n",
       "      <th>cv_prec_mean</th>\n",
       "      <th>cv_rec_mean</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_prec</th>\n",
       "      <th>test_rec</th>\n",
       "      <th>test_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>none</td>\n",
       "      <td>recall_micro</td>\n",
       "      <td>rf</td>\n",
       "      <td>[gini, 6, None, 100]</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>none</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>rf</td>\n",
       "      <td>[gini, 6, balanced, 200]</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  size_tr    sm        metric cls                    params tr_f1 tr_prec  \\\n",
       "0    1.00  none  recall_micro  rf      [gini, 6, None, 100]  0.63    0.80   \n",
       "1    1.00  none   f1_weighted  rf  [gini, 6, balanced, 200]  0.78    0.79   \n",
       "\n",
       "  tr_rec cv_f1_mean cv_prec_mean cv_rec_mean test_f1 test_prec test_rec  \\\n",
       "0   0.72       0.59         0.66        0.70    0.58      0.70     0.62   \n",
       "1   0.78       0.65         0.65        0.65    0.61      0.61     0.62   \n",
       "\n",
       "  test_auc  \n",
       "0     0.50  \n",
       "1     0.55  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((dfAux, df))\n",
    "df[[\"size_tr\",\"sm\",\"metric\",\"cls\",\"params\",'tr_f1', 'tr_prec', 'tr_rec', \n",
    "     'cv_f1_mean', 'cv_prec_mean', 'cv_rec_mean', 'test_f1', 'test_prec', \n",
    "        'test_rec', 'test_auc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
