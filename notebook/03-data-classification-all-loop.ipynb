{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TO RE-RUN\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE,ADASYN, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from operator import truediv\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "plt.style.use('classic')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../../src/\") #\"/home/ilmira/healthforecast/readmission/src/\"\n",
    "from TypeFeatImputer import TypeFeatImputer\n",
    "from UnivCombineFilter import UnivCombineFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typeEncounter = \"last\" # ['first','last']\n",
    "typeHypothesis = \"all_readmisssion_vs_none\" # ['all_readmisssion_vs_none','early_readmission_vs_none']\n",
    "typeDataFeatures = \"extended\" # [\"minimum,\"extended']\n",
    "typeDisease = \"subset\" # [\"subset\",\"individual\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71518, 30)\n",
      "Index([u'diss_1', u'adm_src_ref', u'adm_src_em', u'race_AfricanAmerican',\n",
      "       u'race_Caucasian', u'race_Other', u'medSpec_cardio',\n",
      "       u'medSpec_Family/GeneralPractice', u'medSpec_InternalMedicine',\n",
      "       u'medSpec_surgery', u'age_cat', u'Diabetis', u'Circulatory',\n",
      "       u'Digestive', u'Genitourinary', u'Poisoning', u'Muscoskeletal',\n",
      "       u'Neoplasms', u'Respiratory', u'HbA1c', u'Change', u'time_in_hospital',\n",
      "       u'num_lab_procedures', u'num_procedures', u'num_medications',\n",
      "       u'number_outpatient', u'number_emergency', u'number_inpatient',\n",
      "       u'number_diagnoses', u'readmitted'],\n",
      "      dtype='object')\n",
      "0    42985\n",
      "2    22240\n",
      "1     6293\n",
      "Name: readmitted, dtype: int64\n",
      "0   0.60\n",
      "2   0.31\n",
      "1   0.09\n",
      "Name: readmitted, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if typeDataFeatures == \"minimum\":\n",
    "    df_all=pd.read_pickle(os.path.join('resources','clean_data_' + typeEncounter + '_hyp_1.pkl'))\n",
    "if typeDataFeatures == \"extended\":\n",
    "    df_all=pd.read_pickle(os.path.join('resources','clean_data_' + typeEncounter + '_hyp_1_' + typeDataFeatures + '.pkl'))\n",
    "    \n",
    "print df_all.shape\n",
    "print df_all.columns\n",
    "print df_all.readmitted.value_counts()\n",
    "print df_all.readmitted.value_counts()/float(df_all.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] 42985 6293 22240\n"
     ]
    }
   ],
   "source": [
    "print df_all.loc[:,\"readmitted\"].sort_values().unique(), \\\n",
    "    np.sum(df_all[\"readmitted\"] == 0), \\\n",
    "    np.sum(df_all[\"readmitted\"] == 1), \\\n",
    "    np.sum(df_all[\"readmitted\"] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_readmisssion_vs_none\n",
      "[0 1] 42985 28533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilmira/.conda/envs/readmision/lib/python2.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Readmitted none vs readmitted\n",
    "print typeHypothesis\n",
    "\n",
    "if typeHypothesis == \"all_readmisssion_vs_none\":\n",
    "    df_all[\"readmitted\"][df_all[\"readmitted\"].values > 0] = 1\n",
    "    print df_all.iloc[:,-1].sort_values().unique(), \\\n",
    "            np.sum(df_all[\"readmitted\"] == 0), \\\n",
    "            np.sum(df_all[\"readmitted\"] == 1)\n",
    "            \n",
    "# Readmitted none vs early readmitted            \n",
    "if typeHypothesis == \"early_readmission_vs_none\":\n",
    "    df_all= df_all[df_all[\"readmitted\"].isin([0,1])]\n",
    "    print df_all.iloc[:,-1].sort_values().unique(), np.sum(df_all[\"readmitted\"] == 0), np.sum(df_all[\"readmitted\"] == 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute type fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat cols: 21 \n",
      "Index([u'diss_1', u'adm_src_ref', u'adm_src_em', u'race_AfricanAmerican',\n",
      "       u'race_Caucasian', u'race_Other', u'medSpec_cardio',\n",
      "       u'medSpec_Family/GeneralPractice', u'medSpec_InternalMedicine',\n",
      "       u'medSpec_surgery', u'age_cat', u'Diabetis', u'Circulatory',\n",
      "       u'Digestive', u'Genitourinary', u'Poisoning', u'Muscoskeletal',\n",
      "       u'Neoplasms', u'Respiratory', u'HbA1c', u'Change'],\n",
      "      dtype='object')\n",
      "Num cols: 8 \n",
      "Index([u'time_in_hospital', u'num_lab_procedures', u'num_procedures',\n",
      "       u'num_medications', u'number_outpatient', u'number_emergency',\n",
      "       u'number_inpatient', u'number_diagnoses'],\n",
      "      dtype='object')\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "if typeDataFeatures == \"minimum\":\n",
    "    numCols = ['time_in_hospital']\n",
    "    \n",
    "if typeDataFeatures == \"extended\":\n",
    "    numCols = ['time_in_hospital','num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', \n",
    "            'number_emergency', 'number_inpatient', 'number_diagnoses']\n",
    "    \n",
    "catCols = []\n",
    "cols = df_all.columns\n",
    "reducedCols = cols[:-1]\n",
    "\n",
    "for i in range(len(cols)-1):\n",
    "    if cols[i] not in numCols:\n",
    "        catCols.append(1)\n",
    "    else:\n",
    "        catCols.append(0)\n",
    "catCols = np.array(catCols)\n",
    "\n",
    "print \"Cat cols:\", np.sum(catCols==1), \"\\n\", reducedCols[catCols==1]\n",
    "print \"Num cols:\", np.sum(catCols==0), \"\\n\", reducedCols[catCols==0]\n",
    "print len(reducedCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute partition (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_thr = 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "0    42985\n",
      "1    28533\n",
      "Name: readmitted, dtype: int64\n",
      "\n",
      "TRAIN:\n",
      "(50062, 29) (50062,)\n",
      "30089 0.6 19973 0.4\n",
      "\n",
      "TEST:\n",
      "(21456, 29) (21456,)\n",
      "12896 0.6 8560 0.4\n"
     ]
    }
   ],
   "source": [
    "y = df_all.readmitted\n",
    "print y.unique()\n",
    "print y.value_counts()\n",
    "y = y.values\n",
    "\n",
    "X = df_all.iloc[:,:-1].values\n",
    "sss = StratifiedShuffleSplit(y, 1, test_size=ts_thr, random_state=32) #random_state=42\n",
    "for train_index, test_index in sss:\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print \"\\nTRAIN:\"\n",
    "print X_train.shape, y_train.shape\n",
    "print np.sum(y_train == 0), round(np.sum(y_train == 0)/float(y_train.shape[0]),2), \\\n",
    "      np.sum(y_train > 0), round(np.sum(y_train > 0)/float(y_train.shape[0]),2)\n",
    "print \"\\nTEST:\"\n",
    "print X_test.shape, y_test.shape\n",
    "print np.sum(y_test == 0), round(np.sum(y_test == 0)/float(y_test.shape[0]),2), \\\n",
    "      np.sum(y_test > 0), round(np.sum(y_test > 0)/float(y_test.shape[0]),2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_thr = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:\n",
      "(10012, 29) (10012,)\n",
      "6018 0.6 3994 0.4\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(y_train, 1, test_size=1-tr_thr, random_state=32) #random_state=42\n",
    "for train_index, test_index in sss:\n",
    "    X_train = X_train[train_index]\n",
    "    y_train = y_train[train_index]\n",
    "    \n",
    "print \"TRAIN:\"\n",
    "print X_train.shape, y_train.shape\n",
    "print np.sum(y_train == 0), round(np.sum(y_train == 0)/float(y_train.shape[0]),2), \\\n",
    "      np.sum(y_train > 0), round(np.sum(y_train > 0)/float(y_train.shape[0]),2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbose = True\n",
    "cv_thr = 0.3\n",
    "cv_folds = 5\n",
    "\n",
    "fs_methods = [\"none\"] #[\"none\",\"combine_fs\",\"lasso_fs\",\"rfe_rf_fs\"]\n",
    "cls_methods = [\"logReg\",\"rf\",\"svmRBF\"] #[\"rf\",\"svmRBF\",\"logReg\",\"knn\",\"nn\"]\n",
    "lms = [\"roc_auc\",\"recall\"] #[\"f1_weighted\",\"precision_weighted\"]\n",
    "sm_types = [\"none\",\"after\"] #[\"none\",\"after\"]\n",
    "sm_method = \"sm_smote\"\n",
    "tr_size = tr_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basePipeline = Pipeline([\n",
    "        (\"Imputer\", TypeFeatImputer(catCols, reducedCols)),\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "        (\"Variance\", VarianceThreshold(threshold=0.0))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = [] \n",
    "\n",
    "for fs_method in fs_methods:\n",
    "    for sm_type in sm_types:\n",
    "        for cls_method in cls_methods:\n",
    "            for lm in lms:\n",
    "                if not (fs_method == \"rfe_rf_fs\" and cls_method == \"rf\"):\n",
    "                    params = {}   \n",
    "                    pipe = Pipeline(list(basePipeline.steps))\n",
    "\n",
    "                    if fs_method == \"combine_fs\":\n",
    "                        pipe.steps.insert(1,(fs_method, UnivCombineFilter(catCols,np.array(reducedCols))))\n",
    "                        params.update({fs_method + '__percentile':[5,10,20,30,40,50]})\n",
    "\n",
    "                    if fs_method == \"rfe_rf_fs\":\n",
    "                        pipe.steps.append((fs_method, RFE(estimator=RandomForestClassifier(class_weight='balanced',\n",
    "                                                                                           n_estimators=100,\n",
    "                                                                                           random_state=33))))\n",
    "                        params.update({fs_method + '__step':[0.1]})\n",
    "                        params.update({fs_method + '__n_features_to_select':[\n",
    "                                                        int(len(reducedCols)*0.4), \n",
    "                                                        int(len(reducedCols)*0.6), \n",
    "                                                        int(len(reducedCols)*0.8)]})\n",
    "\n",
    "                    if fs_method == 'lasso_fs':\n",
    "                        pipe.steps.append((fs_method, SelectFromModel(\n",
    "                                    LogisticRegression(n_jobs=-1, penalty=\"l1\", dual=False, random_state=42))))\n",
    "                        params.update({fs_method + '__estimator__C': [0.001,0.01,0.1,1]})\n",
    "\n",
    "                    #Add classifiers\n",
    "                    if cls_method == \"knn\":\n",
    "                        pipe.steps.append((cls_method, KNeighborsClassifier()))\n",
    "                        params.update({'knn__n_neighbors':[1,3,5,7,9,11], 'knn__weights':['uniform', 'distance']})\n",
    "\n",
    "                    if cls_method == \"logReg\":\n",
    "                        pipe.steps.append((cls_method, LogisticRegression(random_state=42)))\n",
    "                        params.update({'logReg__C': [0.00001,0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,15,30]})\n",
    "                        params.update({'logReg__class_weight': [None, 'balanced']})\n",
    "                        params.update({'logReg__penalty': ['l1', 'l2']})\n",
    "\n",
    "                    if cls_method == \"svmRBF\":\n",
    "                        pipe.steps.append((cls_method, SVC(random_state=42,probability=True)))\n",
    "                        params.update({'svmRBF__C': [0.01,0.1,0.5,1,5,10,30,50,100], \n",
    "                         'svmRBF__gamma' : [0.0001,0.001,0.01, 0.1,1,5]})\n",
    "                        params.update({'svmRBF__class_weight': [None, 'balanced']})\n",
    "\n",
    "                    if cls_method == \"rf\":\n",
    "                        pipe.steps.append((cls_method, RandomForestClassifier(n_jobs=-1,random_state=42)))\n",
    "                        params.update({'rf__n_estimators': [100,150,200,250,500], \n",
    "                                       'rf__criterion': ['entropy','gini'],\n",
    "                                       'rf__max_depth' : [None,4,6]})\n",
    "                        params.update({'rf__class_weight': [None, 'balanced']})\n",
    "\n",
    "                    if cls_method == \"nn\":\n",
    "                        pipe.steps.append((cls_method, MLPClassifier(\n",
    "                                    activation='logistic',\n",
    "                                    solver='lbfgs', \n",
    "                                    hidden_layer_sizes=(5, 2), \n",
    "                                    random_state=13)))\n",
    "                        params.update({\n",
    "                                'nn__alpha': [1e-5,0.00001,0.0001,0.001,0.01,0.1,1,3,5,10],\n",
    "                                'nn__hidden_layer_sizes':[(30,),(50,),(70,),(100,),(150,),\n",
    "                                                          (30,30),(50,50),(70,70),(100,100),\n",
    "                                                          (30,30,30),(50,50,50),(70,70,70)\n",
    "                                                         ]\n",
    "                                      })\n",
    "\n",
    "                    #Add sampling\n",
    "                    pipe_imb = make_pipeline(*[p[1] for p in pipe.steps])\n",
    "                    stps = len(pipe_imb.steps)        \n",
    "                    for s in range(stps):\n",
    "                        pipe_imb.steps.remove(pipe_imb.steps[0])\n",
    "                    for s in range(stps):\n",
    "                        pipe_imb.steps.append(pipe.steps[s])\n",
    "\n",
    "                    if sm_type == \"after\":                    \n",
    "                        pipe_imb.steps.insert(stps - 1, \n",
    "                                              (sm_method, SMOTE(ratio='auto', kind='regular', random_state=32)))\n",
    "                        params.update({sm_method + \"__k_neighbors\":[3,4,5]})\n",
    "\n",
    "\n",
    "                    pipeline.append([fs_method,sm_type,cls_method,lm,pipe_imb,params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fs</th>\n",
       "      <th>sm</th>\n",
       "      <th>cls</th>\n",
       "      <th>metric</th>\n",
       "      <th>pipe</th>\n",
       "      <th>pipe_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>logReg</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'logReg__class_weight': [None, u'balanced'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>logReg</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'logReg__class_weight': [None, u'balanced'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>rf</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'rf__criterion': [u'entropy', u'gini'], u'rf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>rf</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'rf__criterion': [u'entropy', u'gini'], u'rf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>svmRBF</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>svmRBF</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>logReg</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'logReg__class_weight': [None, u'balanced'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>logReg</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'logReg__class_weight': [None, u'balanced'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>rf</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'rf__criterion': [u'entropy', u'gini'], u'rf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>rf</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'rf__criterion': [u'entropy', u'gini'], u'rf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>svmRBF</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>none</td>\n",
       "      <td>after</td>\n",
       "      <td>svmRBF</td>\n",
       "      <td>recall</td>\n",
       "      <td>Pipeline(memory=None,\\n     steps=[('Imputer',...</td>\n",
       "      <td>{u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fs     sm     cls   metric  \\\n",
       "0   none   none  logReg  roc_auc   \n",
       "1   none   none  logReg   recall   \n",
       "2   none   none      rf  roc_auc   \n",
       "3   none   none      rf   recall   \n",
       "4   none   none  svmRBF  roc_auc   \n",
       "5   none   none  svmRBF   recall   \n",
       "6   none  after  logReg  roc_auc   \n",
       "7   none  after  logReg   recall   \n",
       "8   none  after      rf  roc_auc   \n",
       "9   none  after      rf   recall   \n",
       "10  none  after  svmRBF  roc_auc   \n",
       "11  none  after  svmRBF   recall   \n",
       "\n",
       "                                                 pipe  \\\n",
       "0   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "1   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "2   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "3   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "4   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "5   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "6   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "7   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "8   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "9   Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "10  Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "11  Pipeline(memory=None,\\n     steps=[('Imputer',...   \n",
       "\n",
       "                                          pipe_params  \n",
       "0   {u'logReg__class_weight': [None, u'balanced'],...  \n",
       "1   {u'logReg__class_weight': [None, u'balanced'],...  \n",
       "2   {u'rf__criterion': [u'entropy', u'gini'], u'rf...  \n",
       "3   {u'rf__criterion': [u'entropy', u'gini'], u'rf...  \n",
       "4   {u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...  \n",
       "5   {u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...  \n",
       "6   {u'logReg__class_weight': [None, u'balanced'],...  \n",
       "7   {u'logReg__class_weight': [None, u'balanced'],...  \n",
       "8   {u'rf__criterion': [u'entropy', u'gini'], u'rf...  \n",
       "9   {u'rf__criterion': [u'entropy', u'gini'], u'rf...  \n",
       "10  {u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...  \n",
       "11  {u'svmRBF__gamma': [0.0001, 0.001, 0.01, 0.1, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pd.DataFrame(pipeline, columns=[\"fs\",\"sm\",\"cls\",\"metric\",\"pipe\",\"pipe_params\"])\n",
    "pipeline.sort_values(\"fs\", inplace=True)\n",
    "print pipeline.shape\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL TRAIN: (10012, 29)\n",
      "TRAIN: [0's: 6018 1's: 3994 ]\n",
      "ALL TEST: (21456, 29)\n",
      "TEST: [0's: 12896 1's: 8560 ]\n",
      "\n",
      " Num experiment: 0\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: logReg\n",
      "METRIC: roc_auc\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV INNER metric: roc_auc\n",
      "CV INNER selected params ['balanced', 0.1, 'l1']\n",
      "CV INNER score: 0.640156952248\n",
      "\n",
      "CV OUTER f1 score: 0.611  (+/-0.002)\n",
      "CV OUTER prec score: 0.615  (+/-0.002)\n",
      "CV OUTER rec score: 0.609  (+/-0.002)\n",
      "Selected params (bests from CV) ['balanced', 0.1, 'l1']\n",
      "\n",
      "TR F1 score: 0.613508981989\n",
      "TR Prec score: 0.617074862762\n",
      "TR Rec score: 0.611266480224\n",
      "\n",
      "Test f1: 0.604\n",
      "Test Precision: 0.602\n",
      "Test Recall: 0.608\n",
      "Test AUC: 0.592\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.64      0.66     12896\n",
      "          1       0.50      0.54      0.52      8560\n",
      "\n",
      "avg / total       0.61      0.60      0.60     21456\n",
      "\n",
      "[[8291 4605]\n",
      " [3933 4627]]\n",
      "\n",
      "Total time: 24.8265180588\n",
      "\n",
      " Num experiment: 1\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: logReg\n",
      "METRIC: recall\n",
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV INNER metric: recall\n",
      "CV INNER selected params ['balanced', 1e-05, 'l2']\n",
      "CV INNER score: 0.590150250417\n",
      "\n",
      "CV OUTER f1 score: 0.585  (+/-0.005)\n",
      "CV OUTER prec score: 0.599  (+/-0.004)\n",
      "CV OUTER rec score: 0.581  (+/-0.005)\n",
      "Selected params (bests from CV) ['balanced', 1e-05, 'l2']\n",
      "\n",
      "TR F1 score: 0.589388469718\n",
      "TR Prec score: 0.601976951578\n",
      "TR Rec score: 0.585197762685\n",
      "\n",
      "Test f1: 0.583\n",
      "Test Precision: 0.579\n",
      "Test Recall: 0.595\n",
      "Test AUC: 0.578\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.58      0.62     12896\n",
      "          1       0.48      0.57      0.52      8560\n",
      "\n",
      "avg / total       0.60      0.58      0.58     21456\n",
      "\n",
      "[[7514 5382]\n",
      " [3645 4915]]\n",
      "\n",
      "Total time: 24.6503970623\n",
      "\n",
      " Num experiment: 2\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: roc_auc\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV INNER metric: roc_auc\n",
      "CV INNER selected params ['entropy', 6, None, 500]\n",
      "CV INNER score: 0.644915436765\n",
      "\n",
      "CV OUTER f1 score: 0.559  (+/-0.005)\n",
      "CV OUTER prec score: 0.635  (+/-0.010)\n",
      "CV OUTER rec score: 0.631  (+/-0.004)\n",
      "Selected params (bests from CV) ['entropy', 6, None, 500]\n",
      "\n",
      "TR F1 score: 0.589288279436\n",
      "TR Prec score: 0.68434205514\n",
      "TR Rec score: 0.654514582501\n",
      "\n",
      "Test f1: 0.557\n",
      "Test Precision: 0.629\n",
      "Test Recall: 0.629\n",
      "Test AUC: 0.551\n",
      "with following performance in test:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.94      0.75     12896\n",
      "          1       0.63      0.17      0.26      8560\n",
      "\n",
      "avg / total       0.63      0.63      0.56     21456\n",
      "\n",
      "[[12058   838]\n",
      " [ 7130  1430]]\n",
      "\n",
      "Total time: 112.443551064\n",
      "\n",
      " Num experiment: 3\n",
      "****************\n",
      "FS: none\n",
      "SM: none\n",
      "CLS: rf\n",
      "METRIC: recall\n",
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.9s\n"
     ]
    }
   ],
   "source": [
    "print \"ALL TRAIN:\", X_train.shape\n",
    "print \"TRAIN:\", \"[0's:\", np.sum(y_train==0), \"1's:\", np.sum(y_train==1), \"]\"\n",
    "print \"ALL TEST:\", X_test.shape\n",
    "print \"TEST:\", \"[0's:\", np.sum(y_test==0), \"1's:\", np.sum(y_test==1), \"]\"\n",
    "\n",
    "results = []\n",
    "#folder = os.path.join('resources','results', datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "#os.makedirs(folder)\n",
    "\n",
    "for num_exp in range(pipeline.shape[0]):\n",
    "\n",
    "    # Run experiment\n",
    "    start = time.time()\n",
    "\n",
    "    #Prepare pipe_cls      \n",
    "    pipeline_cls = pipeline[\"pipe\"].iloc[num_exp]\n",
    "    pipeline_params = pipeline[\"pipe_params\"].iloc[num_exp]\n",
    "    fs = pipeline[\"fs\"].iloc[num_exp]\n",
    "    sm = pipeline[\"sm\"].iloc[num_exp]\n",
    "    cls = pipeline[\"cls\"].iloc[num_exp]\n",
    "    lm = pipeline[\"metric\"].iloc[num_exp]\n",
    "\n",
    "    print \"\\n Num experiment:\", num_exp\n",
    "    print \"****************\"\n",
    "    print \"FS:\",fs\n",
    "    print \"SM:\",sm\n",
    "    print \"CLS:\",cls\n",
    "    print \"METRIC:\",lm\n",
    "\n",
    "    #Prepare cv\n",
    "    cv_inner = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=24)\n",
    "    cv_outer = StratifiedShuffleSplit(y_train, n_iter=cv_folds, test_size=cv_thr, random_state=42)\n",
    "\n",
    "    #Fit pipeline with CV                        \n",
    "    grid_pipeline = GridSearchCV(pipeline_cls, param_grid=pipeline_params, verbose=verbose, \n",
    "                                 n_jobs=-1, cv=cv_inner, scoring= lm, error_score = 0) \n",
    "    grid_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Compute pipeline evaluation with CVmetric\n",
    "    print \"\\nCV INNER metric: {}\".format(lm)\n",
    "    print \"CV INNER selected params {}\".format(grid_pipeline.best_params_.values())\n",
    "    print \"CV INNER score: {}\".format(grid_pipeline.best_score_)\n",
    "\n",
    "    cv_f1 = cross_val_score(grid_pipeline.best_estimator_, X_train, y_train, \n",
    "                                             cv=cv_outer, scoring='f1_weighted', n_jobs=-1)\n",
    "\n",
    "    cv_prec = cross_val_score(grid_pipeline.best_estimator_, X_train, y_train, \n",
    "                                             cv=cv_outer, scoring='precision_weighted', n_jobs=-1)\n",
    "\n",
    "    cv_rec = cross_val_score(grid_pipeline.best_estimator_, X_train, y_train, \n",
    "                                             cv=cv_outer, scoring='recall_weighted', n_jobs=-1)\n",
    "\n",
    "    print \"\\nCV OUTER f1 score: %0.3f  (+/-%0.03f)\" % (np.mean(cv_f1), np.std(cv_f1))\n",
    "    print \"CV OUTER prec score: %0.3f  (+/-%0.03f)\" % (np.mean(cv_prec), np.std(cv_prec))\n",
    "    print \"CV OUTER rec score: %0.3f  (+/-%0.03f)\" % (np.mean(cv_rec), np.std(cv_rec))\n",
    "    print \"Selected params (bests from CV) {}\".format(grid_pipeline.best_params_.values())\n",
    "\n",
    "    # Computel Train score (with best CV params)\n",
    "    y_pred = grid_pipeline.best_estimator_.predict(X_train)\n",
    "    train_prec_scores = metrics.precision_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "    train_rec_scores = metrics.recall_score(y_train, y_pred, average='weighted', pos_label=None)    \n",
    "    train_f1_scores = metrics.f1_score(y_train, y_pred, average='weighted', pos_label=None)\n",
    "\n",
    "    print \"\\nTR F1 score:\", train_f1_scores\n",
    "    print \"TR Prec score:\", train_prec_scores\n",
    "    print \"TR Rec score:\", train_rec_scores\n",
    "\n",
    "    #Compute test score\n",
    "    y_pred = grid_pipeline.best_estimator_.predict(X_test)\n",
    "    test_f1 = metrics.f1_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "    test_prec = metrics.recall_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "    test_rec = metrics.precision_score(y_test, y_pred, average='weighted', pos_label=None)\n",
    "    test_auc = metrics.roc_auc_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print \"\\nTest f1: %0.3f\" % (test_f1)\n",
    "    print \"Test Precision: %0.3f\" % (test_prec)\n",
    "    print \"Test Recall: %0.3f\" % (test_rec)\n",
    "    print \"Test AUC: %0.3f\" % (test_auc)\n",
    "\n",
    "    print \"with following performance in test:\"\n",
    "    print metrics.classification_report(y_test, y_pred)\n",
    "    print metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    end = time.time()\n",
    "    print \"\\nTotal time:\", end - start\n",
    "    results.append([num_exp,\n",
    "                   typeDisease,\n",
    "                   typeEncounter,\n",
    "                   typeHypothesis,\n",
    "                   typeDataFeatures, \n",
    "                   tr_size,\n",
    "                   fs,\n",
    "                   sm,\n",
    "                   cls,\n",
    "                   lm,\n",
    "                   grid_pipeline.best_params_.values(),\n",
    "                   train_f1_scores,\n",
    "                   train_prec_scores,\n",
    "                   train_rec_scores,\n",
    "                   np.mean(cv_f1), \n",
    "                   np.std(cv_f1),\n",
    "                   np.mean(cv_prec), \n",
    "                   np.std(cv_prec),\n",
    "                   np.mean(cv_rec), \n",
    "                   np.std(cv_rec),                    \n",
    "                   test_f1,\n",
    "                   test_prec,\n",
    "                   test_rec,\n",
    "                   test_auc,                    \n",
    "                   end - start,\n",
    "                   grid_pipeline.best_estimator_\n",
    "                  ])\n",
    "\n",
    "    #Save results\n",
    "    df = pd.DataFrame(results, columns=\n",
    "              [\"exp\", \"typeDisease\",\"typeEncounter\",\"typeHypothesis\",\"typeDataFeatures\",\n",
    "               \"size_tr\",\"fs\",\"sm\",\"cls\",\"metric\",\"params\",\n",
    "               \"tr_f1\",\"tr_prec\",\"tr_rec\",\n",
    "               \"cv_f1_mean\",\"cv_f1_std\",\"cv_prec_mean\",\"cv_prec_std\",\"cv_rec_mean\",\"cv_rec_std\",\n",
    "               \"test_f1\",\"test_prec\",\"test_rec\",\"test_auc\",\n",
    "               \"time\",\"pipeline\"])\n",
    "\n",
    "    df.to_pickle(os.path.join(\"resources\", \"results\",\n",
    "                              'results_pipe_' + \n",
    "                              \"test_\" + str(ts_thr) + \"_\" +\n",
    "                              \"train_\" + str(tr_thr) + \"_\" +\n",
    "                              str(typeDisease) + '_' +\n",
    "                              str(typeEncounter) + '_' +\n",
    "                              str(typeHypothesis) + '_' +\n",
    "                              str(typeDataFeatures) + '_' +\n",
    "                              str(num_exp) + '.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=\n",
    "                  [\"exp\",\n",
    "                   \"typeDisease\",\"typeEncounter\",\"typeHypothesis\",\"typeDataFeatures\",\n",
    "                   \"size_tr\",\"fs\",\"sm\",\"cls\",\"metric\",\"params\",\n",
    "                   \"tr_f1\",\"tr_prec\",\"tr_rec\",\n",
    "                   \"cv_f1_mean\",\"cv_f1_std\",\"cv_prec_mean\",\"cv_prec_std\",\"cv_rec_mean\",\"cv_rec_std\",\n",
    "                   \"test_f1\",\"test_prec\",\"test_rec\",\"test_auc\",\n",
    "                   \"time\",\"pipeline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"cv_f1_mean\", ascending=False).head(10).iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
